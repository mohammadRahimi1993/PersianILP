{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "1DvjSVCDHmZz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!pip uninstall -y numpy\n",
        "!pip cache purge\n",
        "!pip install numpy==1.26.4\n",
        "clear_output()\n",
        "print(\"Numpy install successful!\")\n",
        "\n",
        "import os\n",
        "import IPython\n",
        "os._exit(0)"
      ],
      "metadata": {
        "id": "BuOya1ZL61rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/torch-2.2/repo.html\n",
        "!pip install torchmetrics==1.2.1 transformers==4.38.0\n",
        "!pip install torcheval\n",
        "!pip install scikit-learn\n",
        "!pip install deep-translator\n",
        "clear_output()\n",
        "\n",
        "import os\n",
        "import dgl\n",
        "import torch\n",
        "import torchmetrics\n",
        "import transformers\n",
        "import torcheval\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "os.environ['DGLBACKEND'] = \"pytorch\"\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "try:\n",
        "    import dgl\n",
        "    import dgl.graphbolt as gb\n",
        "    installed = True\n",
        "except ImportError as error:\n",
        "    installed = False\n",
        "    print(error)\n",
        "\n",
        "print(\"DGL installed!\" if installed else \"DGL not found!\")\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"TorchMetrics Version: \", torchmetrics.__version__)\n",
        "print(\"Transformers Version: \", transformers.__version__)\n",
        "print(\"DGL Version: \", dgl.__version__)\n",
        "print(\"TorchEval Is: \", torcheval.__version__)"
      ],
      "metadata": {
        "id": "Yg69giwm7IKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1- Create PersianILP"
      ],
      "metadata": {
        "id": "1DvjSVCDHmZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extrac Zip File**"
      ],
      "metadata": {
        "id": "ojMxG3fE7OaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/SPARQL.zip\"\n",
        "extract_path = \"/content/extracted_excels\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "excel_files = [os.path.join(extract_path, f) for f in os.listdir(extract_path) if f.endswith('.xlsx') or f.endswith('.xls')]\n",
        "merged_df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "30rp51NcVLy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Incomplete Triple**"
      ],
      "metadata": {
        "id": "TuoL5jzA7UmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# تنظیمات اولیه\n",
        "extract_path = \"/content/extracted_excels\"\n",
        "output_path = \"/content/FarsiBase\"\n",
        "os.makedirs(output_path, exist_ok=True)  # ایجاد پوشه خروجی اگر وجود نداشته باشد\n",
        "\n",
        "# یافتن و ادغام تمام فایل‌های CSV\n",
        "csv_files = [os.path.join(extract_path, f) for f in os.listdir(extract_path) if f.lower().endswith('.csv')]\n",
        "print(f\"🔎 تعداد فایل‌های CSV یافت‌شده: {len(csv_files)}\")\n",
        "\n",
        "# خواندن و ادغام تمام فایل‌ها\n",
        "merged_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
        "merged_df.to_csv('/content/mergeData', index=False, encoding='utf-8-sig')\n",
        "print(\"✅ تمام فایل‌ها با موفقیت ادغام شدند.\\n\")\n",
        "\n",
        "# گزارش کامل از دیتافریم ادغام شده\n",
        "print(\"📊 گزارش کامل دیتافریم ادغام شده:\")\n",
        "print(\"=================================\")\n",
        "print(f\"➡ تعداد کل ردیف‌ها: {len(merged_df):,}\")\n",
        "print(f\"➡ تعداد کل ستون‌ها: {len(merged_df.columns)}\")\n",
        "print(\"\\n🔹 تعداد مقادیر null در هر ستون:\")\n",
        "print(merged_df.isnull().sum())\n",
        "\n",
        "# تابع ساده‌سازی URI\n",
        "def simplify_uri(uri):\n",
        "    if isinstance(uri, str):\n",
        "        return uri.strip().split(\"/\")[-1].split(\"#\")[-1]  # بهبود برای هندل کردن URIهای مختلف\n",
        "    return uri\n",
        "\n",
        "# اعمال ساده‌سازی روی ستون‌ها\n",
        "cols_to_simplify = [\"subjectLabel\", \"predicateLabel\", \"objectLabel\"]\n",
        "simplified_df = merged_df.copy()\n",
        "for col in cols_to_simplify:\n",
        "    simplified_df[col] = simplified_df[col].apply(simplify_uri)\n",
        "\n",
        "#  حذف موارد تکراری و خالی\n",
        "simplified_df.drop_duplicates(inplace=True)\n",
        "simplified_df = simplified_df.dropna(how='all')\n",
        "print(f\"\\n♻ تعداد ردیف‌ها پس از حذف موارد تکراری: {len(simplified_df):,}\")\n",
        "\n",
        "# محاسبه تعداد فیلدهای پر شده\n",
        "simplified_df[\"filled_count\"] = simplified_df[cols_to_simplify].notna().sum(axis=1)\n",
        "\n",
        "# ذخیره فایل‌های مختلف بر اساس کامل بودن داده‌ها\n",
        "complete_df = simplified_df[simplified_df[\"filled_count\"] == 3].drop(columns=[\"filled_count\"])\n",
        "complete_path = os.path.join(output_path, \"complete_triples.csv\")\n",
        "complete_df.to_csv(complete_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"\\n💾 فایل triples کامل ({len(complete_df):,} ردیف) در {complete_path} ذخیره شد.\")\n",
        "\n",
        "two_filled_df = simplified_df[simplified_df[\"filled_count\"] == 2].drop(columns=[\"filled_count\"])\n",
        "two_path = os.path.join(output_path, \"triples_with_two_values.csv\")\n",
        "two_filled_df.to_csv(two_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"💾 فایل triples با دو مقدار ({len(two_filled_df):,} ردیف) در {two_path} ذخیره شد.\")\n",
        "\n",
        "one_filled_df = simplified_df[simplified_df[\"filled_count\"] == 1].drop(columns=[\"filled_count\"])\n",
        "one_path = os.path.join(output_path, \"triples_with_one_value.csv\")\n",
        "one_filled_df.to_csv(one_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"💾 فایل triples با یک مقدار ({len(one_filled_df):,} ردیف) در {one_path} ذخیره شد.\")\n",
        "\n",
        "# گزارش نهایی\n",
        "print(\"\\n🎉 پردازش با موفقیت به پایان رسید!\")\n",
        "print(f\"\\n📝 گزارش نهایی:\\n{simplified_df.count()}\")"
      ],
      "metadata": {
        "id": "BxgnSL28HR1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FarsiBase Data Cleaning**"
      ],
      "metadata": {
        "id": "32kahtRBEVCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def convert_persian_to_english(number):\n",
        "    persian_to_english = str.maketrans('۰۱۲۳۴۵۶۷۸۹', '0123456789')\n",
        "    return str(number).translate(persian_to_english)\n",
        "\n",
        "df = pd.read_csv(\"/content/FarsiBase/complete_triples.csv\")\n",
        "for column in ['subjectLabel', 'predicateLabel', 'objectLabel']:\n",
        "    df[column] = df[column].apply(convert_persian_to_english)\n",
        "\n",
        "# Clean Relation\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^dcterms#subject','موضوع/محتوا', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^subject','موضوع', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^birth place','محل تولد', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^birth_place','محل تولد', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^birthPlace','محل تولد', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^instanceOf','نمونه‌ای از', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^deathPlace','محل مرگ', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^death place','محل مرگ', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^field','موضوع', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^genre','ژانر', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^nationality','ملیت', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^occupation','شغل', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^picture','تصویر', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^ActiveYears','سال‌های فعالیت', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^activeYears','سال‌های فعالیت', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^timezone1 dst','ناحیه زمانی ۱', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^confed_cup','جام کنفدراسیون', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^distance to London (μ)','فاصله تا لندن (میانگین)', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^fs_date','تاریخ سیستم فایل', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^państwo','کشور', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^państwo','کشور', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^sp_date','تاریخ طرح', regex=True)\n",
        "\n",
        "df = df.drop(df[df['predicateLabel'] == '22-rdf-syntax-ns#instanceOf'].index)\n",
        "df = df[~df['objectLabel'].str.contains('relation', case=False, na=False)]\n",
        "df = df[~df['objectLabel'].str.endswith('.JPG')] # Delete Row with .JPG Value\n",
        "df = df[~df['objectLabel'].str.endswith('.jpg')]\n",
        "df = df[~df['objectLabel'].str.endswith('.png')]\n",
        "df = df[~df['objectLabel'].str.endswith('.svg')]\n",
        "df = df[~df['objectLabel'].str.endswith('Pages_using_infobox3cols_with_multidatastyle')]\n",
        "df = df[~df['objectLabel'].str.endswith(':hy:Սյուզան_Գարագաշ')]\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^Actor','بازیگر', regex=True)\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^Ali_Daei','علی دایی', regex=True)\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^Person','شخص', regex=True)\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^SoccerPlayer','بازیکن سوکر', regex=True)\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^Writer','نویسنده', regex=True)\n",
        "\n",
        "# Remove duplicate row\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.to_csv(\"/content/FarsiBase/complete_triples.csv\", index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "QTl059UlE-Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Shuffling And Aggregation(FarsiBase + Deepseek)**"
      ],
      "metadata": {
        "id": "6V8X0yhUvSiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Aggregate FarsiBase Data And DeepSeek Data\n",
        "DeepSeek_df = pd.read_excel('/content/DeepSeek_Triple.xlsx')\n",
        "input_file = '/content/FarsiBase/complete_triples.csv'\n",
        "FarsiBase_df = pd.read_csv(input_file)\n",
        "df = pd.concat([DeepSeek_df, FarsiBase_df], axis=0)\n",
        "\n",
        "# Shuffled Data\n",
        "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "output_file = '/content/FarsiBase/shuffled_triple.csv'\n",
        "shuffled_df.to_csv(output_file ,index=False , encoding='utf-8-sig')\n",
        "print(f\"فایل اکسل به صورت تصادفی به هم ریخته و در '{output_file}' ذخیره شد.\")"
      ],
      "metadata": {
        "id": "PFoAdlUVOuVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PersianILP Normalizing**"
      ],
      "metadata": {
        "id": "maF_LYoZZNdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# Translate Google\n",
        "def translate_relation(relation, target_lang=\"fa\"):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source='auto', target=target_lang).translate(relation)\n",
        "        return translated\n",
        "    except Exception as e:\n",
        "        print(f\"خطا در ترجمه '{relation}': {e}\")\n",
        "        return relation\n",
        "\n",
        "# Translate Data\n",
        "def normalize_excel(input_path, output_path, use_translation=False):\n",
        "\n",
        "    df = pd.read_csv(input_path)\n",
        "    normalized_relations = []\n",
        "    for relation in df['predicateLabel']:\n",
        "        if pd.isna(relation):\n",
        "            normalized = relation\n",
        "        else:\n",
        "            relation = str(relation)\n",
        "            if use_translation and relation.isascii():\n",
        "              normalized = translate_relation(relation)\n",
        "            else:\n",
        "              normalized = relation\n",
        "        normalized_relations.append(normalized)\n",
        "    df['predicateLabel'] = normalized_relations\n",
        "\n",
        "    # Delete Duplicate Row And Shuffling Data\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"داده‌های نرمال‌سازی شده در '{output_path}' ذخیره شد.\")\n",
        "\n",
        "input_excel = \"/content/FarsiBase/shuffled_triple.csv\"\n",
        "output_excel = \"/content/FarsiBase/triple.csv\"\n",
        "normalize_excel(input_path=input_excel,\n",
        "                output_path=output_excel,\n",
        "                use_translation=True)"
      ],
      "metadata": {
        "id": "FX9LuNEXPUsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from collections import Counter\n",
        "\n",
        "def analyze_dataset_for_link_prediction(file_path):\n",
        "\n",
        "    # 1. خواندن داده‌ها\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, names=['subject', 'predicate', 'object'])\n",
        "        print(f\"✅ دیتاست با موفقیت خوانده شد. تعداد سه‌تایی‌ها: {len(df):,}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ خطا در خواندن فایل: {e}\")\n",
        "        return\n",
        "\n",
        "    # 2. محاسبه معیارهای پایه\n",
        "    num_entities = len(set(df['subject']).union(set(df['object'])))\n",
        "    num_relations = len(set(df['predicate']))\n",
        "    print(f\"\\n📊 آماره‌های پایه:\")\n",
        "    print(f\"تعداد موجودیت‌های منحصر به فرد: {num_entities:,}\")\n",
        "    print(f\"تعداد روابط منحصر به فرد: {num_relations:,}\")\n",
        "\n",
        "    # 3. ایجاد گراف\n",
        "    G = nx.MultiDiGraph()  # گراف جهت‌دار با امکان چندین یال بین گره‌ها\n",
        "    for _, row in df.iterrows():\n",
        "        G.add_edge(row['subject'], row['object'], key=row['predicate'])\n",
        "\n",
        "    # 4. تحلیل درجه گره‌ها\n",
        "    degrees = dict(G.degree())\n",
        "    degree_counts = Counter(degrees.values())\n",
        "\n",
        "    print(\"\\n📈 توزیع درجه گره‌ها:\")\n",
        "    print(f\"• گره‌های با درجه ۱: {degree_counts.get(1, 0):,} ({degree_counts.get(1, 0)/G.number_of_nodes():.1%})\")\n",
        "    print(f\"• گره‌های با درجه ۲: {degree_counts.get(2, 0):,} ({degree_counts.get(2, 0)/G.number_of_nodes():.1%})\")\n",
        "    print(f\"• گره‌های با درجه ۳: {degree_counts.get(3, 0):,} ({degree_counts.get(3, 0)/G.number_of_nodes():.1%})\")\n",
        "\n",
        "    # 5. محاسبه معیارهای گراف\n",
        "    density = nx.density(G)\n",
        "    sparsity = 1 - density\n",
        "    avg_degree = sum(degrees.values()) / G.number_of_nodes()\n",
        "    print(\"\\n🔍 معیارهای ساختاری گراف:\")\n",
        "    print(f\"تعداد گره‌ها: {G.number_of_nodes():,}\")\n",
        "    print(f\"تعداد یال‌ها: {G.number_of_edges():,}\")\n",
        "    print(f\"چگالی گراف: {density:.6f}\")\n",
        "    print(f\"اسپارس بودن: {sparsity:.4f}\")\n",
        "    print(f\"میانگین درجه گره‌ها: {avg_degree:.2f}\")\n",
        "\n",
        "    # 6. بررسی اتصالات\n",
        "    if nx.is_weakly_connected(G):\n",
        "        print(\"\\n🔄 گراف به صورت ضعیف متصل است\")\n",
        "    else:\n",
        "        components = nx.number_weakly_connected_components(G)\n",
        "        print(f\"\\n🔗 گراف دارای {components} جزء ناهمبند است\")\n",
        "\n",
        "    # 7. تحلیل نهایی برای پیش‌بینی پیوند\n",
        "    print(\"\\n🧪 ارزیابی مناسب بودن برای پیش‌بینی پیوند:\")\n",
        "\n",
        "    suitability_score = 0\n",
        "\n",
        "    # معیار 1: تنوع روابط\n",
        "    if num_relations > 50:\n",
        "        print(f\"✓ تنوع روابط عالی ({num_relations} نوع رابطه)\")\n",
        "        suitability_score += 2\n",
        "    elif num_relations > 10:\n",
        "        print(f\"✓ تنوع روابط قابل قبول ({num_relations} نوع رابطه)\")\n",
        "        suitability_score += 1\n",
        "    else:\n",
        "        print(f\"✗ تنوع روابط ناکافی ({num_relations} نوع رابطه)\")\n",
        "\n",
        "    # معیار 2: اسپارس بودن\n",
        "    if sparsity > 0.99:\n",
        "        print(\"✓ اسپارس بودن ایده‌آل (بسیار مناسب برای پیش‌بینی پیوند)\")\n",
        "        suitability_score += 2\n",
        "    elif sparsity > 0.95:\n",
        "        print(\"✓ اسپارس بودن قابل قبول\")\n",
        "        suitability_score += 1\n",
        "    else:\n",
        "        print(\"✗ اسپارس بودن ناکافی\")\n",
        "\n",
        "    # معیار 3: توزیع درجه\n",
        "    if degree_counts.get(1, 0) < G.number_of_nodes() * 0.4:\n",
        "        print(\"✓ توزیع درجه متعادل\")\n",
        "        suitability_score += 1\n",
        "    else:\n",
        "        print(f\"✗ توزیع درجه نامتعادل ({degree_counts.get(1, 0)/G.number_of_nodes():.1%} گره‌ها درجه ۱ دارند)\")\n",
        "\n",
        "    # نتیجه‌گیری نهایی\n",
        "    print(\"\\n🎯 نتیجه‌گیری نهایی:\")\n",
        "    if suitability_score >= 4:\n",
        "        print(\"✅ این دیتاست برای پیش‌بینی پیوند بسیار مناسب است\")\n",
        "    elif suitability_score >= 2:\n",
        "        print(\"⚠️ این دیتاست برای پیش‌بینی پیوند نیاز به بهبودهایی دارد\")\n",
        "    else:\n",
        "        print(\"❌ این دیتاست برای پیش‌بینی پیوند مناسب نیست\")\n",
        "\n",
        "# نمونه استفاده\n",
        "analyze_dataset_for_link_prediction('/content/FarsiBase/triple.csv')"
      ],
      "metadata": {
        "id": "8oanAMglgtPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting three variants of the main dataset**"
      ],
      "metadata": {
        "id": "Tv2JpTGELWsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.makedirs('/content/PersianILP', exist_ok=True)\n",
        "df = pd.read_csv('/content/FarsiBase/triple.csv')\n",
        "n = len(df)\n",
        "idx1 = int(0.25 * n)\n",
        "idx2 = int(0.60 * n)\n",
        "\n",
        "part1 = df.iloc[:idx1].to_csv('/content/PersianILP/PersianILP_V1.csv', index=False, encoding='utf-8-sig')\n",
        "part2 = df.iloc[idx1:idx2].to_csv('/content/PersianILP/PersianILP_V2.csv', index=False, encoding='utf-8-sig')\n",
        "part3 = df.iloc[idx2:].to_csv('/content/PersianILP/PersianILP_V3.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "0Jhms9RWzrC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# تفکیک مجموعه‌ی آموزش و تست\n",
        "def split_train_test_for_file(file_path, test_size=0.2):\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    subjects = set(df.iloc[:, 0].dropna().unique())\n",
        "    objects = set(df.iloc[:, 2].dropna().unique())\n",
        "    all_entities = subjects.union(objects)\n",
        "\n",
        "    train_entities, test_entities = train_test_split(\n",
        "        list(all_entities),\n",
        "        test_size=test_size,\n",
        "        random_state=42)\n",
        "\n",
        "    train_entities = set(train_entities)\n",
        "    test_entities = set(test_entities)\n",
        "\n",
        "    train_mask = df.iloc[:, 0].isin(train_entities) & df.iloc[:, 2].isin(train_entities)\n",
        "    test_mask = df.iloc[:, 0].isin(test_entities) & df.iloc[:, 2].isin(test_entities)\n",
        "    train_df = df[train_mask]\n",
        "    test_df = df[test_mask]\n",
        "    return train_df, test_df\n",
        "\n",
        "# ایجاد مجموعه داده‌ی فارسی و انگلیسی استقرایی\n",
        "file_paths = ['/content/PersianILP/PersianILP_V1.csv',\n",
        "              '/content/PersianILP/PersianILP_V2.csv',\n",
        "              '/content/PersianILP/PersianILP_V3.csv']\n",
        "\n",
        "output_dir = '/content/PersianILP-trainTest'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for file_path in file_paths:\n",
        "    base_name = os.path.basename(file_path)\n",
        "    file_name = os.path.splitext(base_name)[0]\n",
        "\n",
        "    version_dir = os.path.join(output_dir, file_name)\n",
        "    os.makedirs(version_dir, exist_ok=True)\n",
        "    train_data, test_data = split_train_test_for_file(file_path, test_size=0.3)\n",
        "\n",
        "    train_output = os.path.join(version_dir, f'train.csv')\n",
        "    test_output = os.path.join(version_dir, f'test.csv')\n",
        "\n",
        "    train_data.to_csv(train_output, index=False, encoding='utf-8-sig')\n",
        "    test_data.to_csv(test_output, index=False, encoding='utf-8-sig')\n",
        "\n",
        "# ایجاد فایل زیپ\n",
        "output_dir = '/content/PersianILP-trainTest'\n",
        "zip_path = os.path.join(output_dir, 'PersianILP-data.zip')\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            if not file.endswith('.zip'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, output_dir)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "print(f\"فایل zip در مسیر زیر ایجاد شد: {zip_path}\")"
      ],
      "metadata": {
        "id": "QPzoXZ1uhcr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ًImport Dataset**"
      ],
      "metadata": {
        "id": "gdmJ5DBNUlK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ILP_Date_Zip_File = '/content/drive/MyDrive/DataSet/Data_InductiveLinkPrediction.zip'\n",
        "TLP_Data_Zip_File = '/content/drive/MyDrive/DataSet/Data_TransductiveLinkPrediciton.zip'\n",
        "\n",
        "!unzip -q {ILP_Date_Zip_File} -d {'/content'}\n",
        "!unzip -q {TLP_Data_Zip_File} -d {'/content'}\n",
        "\n",
        "datasets = sorted([folder for folder in os.listdir('/content') if os.path.isdir(os.path.join('/content', folder))])\n",
        "def create_dataset_dict(base_dir:str='/content'):\n",
        "    datasets = {}\n",
        "    for dataset_name in os.listdir(base_dir):\n",
        "        dataset_path = os.path.join(base_dir, dataset_name)\n",
        "        if os.path.isdir(dataset_path):\n",
        "            datasets[dataset_name] = {\n",
        "                \"train\": os.path.join(dataset_path, \"train.txt\"),\n",
        "                \"valid\": os.path.join(dataset_path, \"valid.txt\"),\n",
        "                \"test\":  os.path.join(dataset_path, \"test.txt\")}\n",
        "    return datasets\n",
        "\n",
        "# Save Path Dictionay\n",
        "ILP_dataset_paths = create_dataset_dict('/content/Data_InductiveLinkPrediction')\n",
        "ILP_dataset_paths = dict(sorted(ILP_dataset_paths.items()))"
      ],
      "metadata": {
        "id": "dP843TcnUuNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis PersianILP With English BencmarkDataset**"
      ],
      "metadata": {
        "id": "sroJUIhpvhWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from collections import Counter\n",
        "from tabulate import tabulate\n",
        "\n",
        "def load_data(file_path):\n",
        "    sep = \",\" if file_path.endswith('.csv') else \"\\t\"\n",
        "    return pd.read_csv(file_path, sep=sep, header=None, names=[\"head\", \"relation\", \"tail\"])\n",
        "\n",
        "def analyze_graph_metrics(file_path):\n",
        "        df = load_data(file_path)\n",
        "        G = nx.MultiDiGraph()\n",
        "        G.add_edges_from(zip(df[\"head\"], df[\"tail\"], df[\"relation\"]))\n",
        "\n",
        "        degrees = dict(G.degree())\n",
        "        counter = Counter(degrees.values())\n",
        "        avg_deg = sum(degrees.values()) / G.number_of_nodes() if G.number_of_nodes() else 0\n",
        "\n",
        "        return {\n",
        "            \"Deg_1\": counter.get(1, 0),\n",
        "            \"Deg_2\": counter.get(2, 0),\n",
        "            \"Deg_3\": counter.get(3, 0),\n",
        "            \"Avg_Degree\": round(avg_deg, 2),\n",
        "            \"Density\": round(nx.density(G), 6),\n",
        "            \"Sparsity\": round(1 - nx.density(G), 6)\n",
        "        }\n",
        "\n",
        "def process_file(file_path, label):\n",
        "    if os.path.isfile(file_path) and file_path.endswith(('.csv', '.txt')):\n",
        "        metrics = analyze_graph_metrics(file_path)\n",
        "        if metrics:\n",
        "            metrics['Dataset'] = label\n",
        "            return metrics\n",
        "    return None\n",
        "\n",
        "def analyze_all_datasets(all_dirs):\n",
        "    results = []\n",
        "    for base_dir in all_dirs:\n",
        "\n",
        "        for root, _, files in os.walk(base_dir):\n",
        "            dataset_name = os.path.basename(root)\n",
        "            for file in files:\n",
        "                path = os.path.join(root, file)\n",
        "                ext = os.path.splitext(file)[1].lower()\n",
        "                label_type = \"CSV\" if ext == '.csv' else \"TXT\"\n",
        "                label = f\"{dataset_name}_{os.path.splitext(file)[0]}\"\n",
        "                result = process_file(path, label)\n",
        "                if result:\n",
        "                    results.append(result)\n",
        "\n",
        "    return pd.DataFrame(results)[[\"Dataset\", \"Deg_1\", \"Deg_2\", \"Deg_3\", \"Avg_Degree\", \"Density\", \"Sparsity\"]]\n",
        "\n",
        "# مقایسه‌ی ساختار مجموعه داده‌های فارسی و انگلیسی\n",
        "all_dirs = [\n",
        "    \"/content/Data_InductiveLinkPrediction\",\n",
        "    \"/content/PersianILP-trainTest\"]\n",
        "df_result = analyze_all_datasets(all_dirs).sort_values(\"Dataset\")\n",
        "print(tabulate(df_result, headers=\"keys\", tablefmt=\"grid\", showindex=False))"
      ],
      "metadata": {
        "id": "91_AbZb-snS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2- Inductive Link Prediction(CoraGraphDataset)"
      ],
      "metadata": {
        "id": "6PysJRsRIEZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "\n",
        "import dgl\n",
        "import dgl.data\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "0-dmoz4Vfnbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]"
      ],
      "metadata": {
        "id": "MuIZg_9Vgq0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.num_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.num_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.num_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.num_edges())\n",
        "test_neg_u, test_neg_v = (\n",
        "    neg_u[neg_eids[:test_size]],\n",
        "    neg_v[neg_eids[:test_size]],)\n",
        "\n",
        "train_neg_u, train_neg_v = (\n",
        "    neg_u[neg_eids[test_size:]],\n",
        "    neg_v[neg_eids[test_size:]],)"
      ],
      "metadata": {
        "id": "1CgM9xxSg727"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ],
      "metadata": {
        "id": "DdxmZFIcgSRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, \"mean\")\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "Ch-KoseJpPAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())"
      ],
      "metadata": {
        "id": "An9qkhsGpUPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata[\"score\"][:, 0]"
      ],
      "metadata": {
        "id": "cKabS4FmpWoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src[\"h\"], edges.dst[\"h\"]], 1)\n",
        "        return {\"score\": self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata[\"score\"]"
      ],
      "metadata": {
        "id": "JqhsI2qIpdoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(train_g.ndata[\"feat\"].shape[1], 16)\n",
        "pred = DotPredictor()\n",
        "\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    )\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return roc_auc_score(labels, scores)\n",
        "\n",
        "def compute_auc_pr(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return average_precision_score(labels, scores)"
      ],
      "metadata": {
        "id": "M_GYqGBspjVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# in this case, loss will in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata[\"feat\"])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "\n",
        "clear_output()\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "\n",
        "    print(\"AUC\", compute_auc(pos_score, neg_score))\n",
        "    print(\"AUC_PR\", compute_auc_pr(pos_score, neg_score))\n",
        "\n",
        "    # set pos_scores and neg_scores\n",
        "    pos_scores = pos_score.squeeze().detach().cpu().tolist()\n",
        "    neg_scores = neg_score.squeeze().detach().cpu().tolist()\n",
        "\n",
        "    # set Labels\n",
        "    targets_pos = torch.ones(len(pos_scores))\n",
        "    targets_neg = torch.zeros(len(neg_scores))\n",
        "    pos_labels = targets_pos.detach().cpu().tolist()\n",
        "    neg_labels = targets_neg.detach().cpu().tolist()\n",
        "\n",
        "    # convert to tensors for further processing\n",
        "    pos_tensor = torch.tensor(pos_scores, dtype=torch.float32).view(-1, 1)\n",
        "    neg_tensor = torch.tensor(neg_scores, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    scores = torch.cat([pos_tensor, neg_tensor], dim=1)  # shape: [batch_size, 2]\n",
        "    scores = torch.softmax(scores, dim=1)\n",
        "    scores = scores.detach().cpu().numpy()\n",
        "\n",
        "    rank = np.argwhere(np.argsort(scores, axis=1)[:, ::-1] == 0)[:, 1] + 1\n",
        "    ranks += rank.tolist()\n",
        "\n",
        "    hit1 = [1 if item <= 1 else 0 for item in rank]\n",
        "    hit3 = [1 if item <= 3 else 0 for item in rank]\n",
        "    hit10 = [1 if item <= 10 else 0 for item in rank]\n",
        "\n",
        "    mrr = np.mean(1.0 / np.array(ranks)).item()\n",
        "    hit1 = np.mean(hit1)\n",
        "    hit3 = np.mean(hit3)\n",
        "    hit10 = np.mean(hit10)\n",
        "    print(f'mrr: {mrr}')\n",
        "    print(f'hit1: {hit1}')\n",
        "    print(f'hit3:{hit3}')\n",
        "    print(f'hit10:{hit10}')"
      ],
      "metadata": {
        "id": "tZMGBguMpkcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3- Inductive Link Prediction(PersianILP)"
      ],
      "metadata": {
        "id": "nPOCJCXwfotg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ILP_Date_Zip_File = '/content/drive/MyDrive/DataSet/ILPDataSet.zip'\n",
        "!unzip -q {ILP_Date_Zip_File} -d {'/content'}\n",
        "\n",
        "datasets = sorted([folder for folder in os.listdir('/content') if os.path.isdir(os.path.join('/content', folder))])\n",
        "def create_dataset_dict(base_dir: str = '/content'):\n",
        "    datasets = {}\n",
        "    for dataset_name in os.listdir(base_dir):\n",
        "        dataset_path = os.path.join(base_dir, dataset_name)\n",
        "        if os.path.isdir(dataset_path):\n",
        "            dataset_files = {\n",
        "                \"train\": None,\n",
        "                \"valid\": None,\n",
        "                \"test\": None}\n",
        "\n",
        "            # Check for both .txt and .csv files\n",
        "            for split in dataset_files.keys():\n",
        "                txt_path = os.path.join(dataset_path, f\"{split}.txt\")\n",
        "                csv_path = os.path.join(dataset_path, f\"{split}.csv\")\n",
        "\n",
        "                if os.path.exists(txt_path):\n",
        "                    dataset_files[split] = txt_path\n",
        "                elif os.path.exists(csv_path):\n",
        "                    dataset_files[split] = csv_path\n",
        "\n",
        "            datasets[dataset_name] = dataset_files\n",
        "\n",
        "    return datasets\n",
        "\n",
        "\n",
        "# Save Path Dictionay\n",
        "ILP_dataset_paths = create_dataset_dict('/content/ILPDataSet')\n",
        "ILP_dataset_paths = dict(sorted(ILP_dataset_paths.items()))"
      ],
      "metadata": {
        "id": "BQ6SLucSJmV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link Prediction By DGL**"
      ],
      "metadata": {
        "id": "NyHsMieP32dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "import pandas as pd\n",
        "from dgl.data import DGLDataset\n",
        "\n",
        "class PersianDGLDataset(DGLDataset):\n",
        "    def __init__(self, train_file, test_file, seed=42):\n",
        "        self.train_file = train_file\n",
        "        self.test_file = test_file\n",
        "        self.seed = seed\n",
        "        self.process()\n",
        "        super().__init__(name=\"PersianLinkPrediction\")\n",
        "\n",
        "    def process(self):\n",
        "        # Initialize mappings\n",
        "        self.entity2id = {}\n",
        "        self.relation2id = {}\n",
        "        ent_id, rel_id = 0, 0\n",
        "\n",
        "        # Process training data\n",
        "        train_triples = self._load_and_process_file(self.train_file, ent_id, rel_id)\n",
        "        ent_id, rel_id = len(self.entity2id), len(self.relation2id)\n",
        "\n",
        "        # Process test data (using same mappings)\n",
        "        test_triples = self._load_and_process_file(self.test_file, ent_id, rel_id)\n",
        "\n",
        "        # Build graphs\n",
        "        self.graphs = {\n",
        "            \"train\": self._build_graph(train_triples),\n",
        "            \"test\": self._build_graph(test_triples)\n",
        "        }\n",
        "\n",
        "    def _load_file(self, file_path):\n",
        "        \"\"\"Load file based on its extension\"\"\"\n",
        "        if file_path.endswith('.csv'):\n",
        "            return pd.read_csv(file_path)\n",
        "        elif file_path.endswith('.txt'):\n",
        "            return pd.read_csv(file_path, sep='\\t', header=None,\n",
        "                             names=['subjectLabel', 'predicateLabel', 'objectLabel'])\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file format. Only .csv and .txt files are supported.\")\n",
        "\n",
        "    def _load_and_process_file(self, file_path, ent_id_start, rel_id_start):\n",
        "        \"\"\"Load and process a single file, updating mappings\"\"\"\n",
        "        triples = []\n",
        "        df = self._load_file(file_path)\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            h, r, t = row['subjectLabel'], row['predicateLabel'], row['objectLabel']\n",
        "\n",
        "            # Update entity mappings\n",
        "            for ent in [h, t]:\n",
        "                if ent not in self.entity2id:\n",
        "                    self.entity2id[ent] = ent_id_start\n",
        "                    ent_id_start += 1\n",
        "\n",
        "            # Update relation mappings\n",
        "            if r not in self.relation2id:\n",
        "                self.relation2id[r] = rel_id_start\n",
        "                rel_id_start += 1\n",
        "\n",
        "            triples.append((\n",
        "                self.entity2id[h],\n",
        "                self.relation2id[r],\n",
        "                self.entity2id[t]))\n",
        "\n",
        "        return triples\n",
        "\n",
        "    def _build_graph(self, triples):\n",
        "        \"\"\"Build DGL graph from triples\"\"\"\n",
        "        src, rel, dst = zip(*triples)\n",
        "        src = torch.tensor(src)\n",
        "        dst = torch.tensor(dst)\n",
        "        rel = torch.tensor(rel)\n",
        "\n",
        "        g = dgl.graph((src, dst), num_nodes=len(self.entity2id))\n",
        "        g.edata[\"e_type\"] = rel\n",
        "        g.edata[\"edge_mask\"] = torch.ones(g.num_edges(), dtype=torch.bool)\n",
        "        g.ndata[\"ntype\"] = torch.zeros(g.num_nodes(), dtype=torch.int)\n",
        "        g.ndata[\"feat\"] = torch.randn(g.num_nodes(), 64)\n",
        "        return g\n",
        "\n",
        "    def __getitem__(self, split):\n",
        "        return self.graphs[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "class GraphBatchDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, graphs, pos_graphs, neg_graphs):\n",
        "        self.graphs = graphs\n",
        "        self.pos_graphs = pos_graphs\n",
        "        self.neg_graphs = neg_graphs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"graph\": self.graphs[idx],\n",
        "            \"pos_graph\": self.pos_graphs[idx],\n",
        "            \"neg_graph\": self.neg_graphs[idx]}\n",
        "\n",
        "\n",
        "dataset = PersianDGLDataset(train_file = ILP_dataset_paths['PersianILP_V1']['train'],\n",
        "                            test_file = ILP_dataset_paths['PersianILP_V1']['test'])\n",
        "train_g = dataset[\"train\"]\n",
        "test_g = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "PUYSCAkJU_26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Positive Graph And Negative Graph**"
      ],
      "metadata": {
        "id": "lg6BZ_u1TYFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import dgl\n",
        "import scipy.sparse as sp\n",
        "from tabulate import tabulate\n",
        "import torch\n",
        "\n",
        "class GraphNegativeSampler:\n",
        "    def __init__(self, train_graph, test_graph, train_neg_ratio=1.0, test_neg_ratio=1.0):\n",
        "        self.train_graph = train_graph\n",
        "        self.test_graph = test_graph\n",
        "        self.train_neg_ratio = train_neg_ratio\n",
        "        self.test_neg_ratio = test_neg_ratio\n",
        "        self.train_pos_g, self.train_neg_g = self._prepare_graphs(train_graph, train_neg_ratio)\n",
        "        self.test_pos_g, self.test_neg_g = self._prepare_graphs(test_graph, test_neg_ratio)\n",
        "\n",
        "    def _generate_negative_samples(self, graph):\n",
        "        u, v = graph.edges()\n",
        "        adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())),\n",
        "                          shape=(graph.num_nodes(), graph.num_nodes()))\n",
        "        return np.where(1 - adj.todense() - np.eye(graph.num_nodes()) != 0)\n",
        "\n",
        "    def _prepare_graphs(self, graph, ratio):\n",
        "        return ( self._create_positive_graph(graph),\n",
        "                 self._create_negative_graph(graph, ratio))\n",
        "\n",
        "    def _create_positive_graph(self, graph):\n",
        "        g = dgl.graph(graph.edges(), num_nodes=graph.num_nodes())\n",
        "        g.edata[\"e_type\"] = graph.edata[\"e_type\"]\n",
        "        g.ndata.update({k: graph.ndata[k] for k in [\"feat\", \"ntype\"]})\n",
        "        return g\n",
        "\n",
        "    def _create_negative_graph(self, graph, ratio):\n",
        "        neg_u, neg_v = self._generate_negative_samples(graph)\n",
        "        num_samples = int(graph.num_edges() * ratio)\n",
        "        replace = len(neg_u) < num_samples\n",
        "        sample_ids = np.random.choice(len(neg_u), num_samples, replace=replace)\n",
        "\n",
        "        g = dgl.graph((neg_u[sample_ids], neg_v[sample_ids]), num_nodes=graph.num_nodes())\n",
        "        g.edata[\"e_type\"] = torch.randint(0, graph.edata[\"e_type\"].max().item()+1, (g.num_edges(),))\n",
        "        g.ndata.update({\n",
        "            \"feat\": graph.ndata[\"feat\"],\n",
        "            \"ntype\": torch.ones(graph.num_nodes(), dtype=torch.int)})\n",
        "        return g\n",
        "\n",
        "    @property\n",
        "    def training_graphs(self):\n",
        "        return self.train_pos_g, self.train_neg_g\n",
        "\n",
        "    @property\n",
        "    def test_graphs(self):\n",
        "        return self.test_pos_g, self.test_neg_g\n",
        "\n",
        "# Sampling From Knowladge Graph\n",
        "sampler = GraphNegativeSampler(dataset['train'],\n",
        "                               dataset['test'],\n",
        "                               train_neg_ratio=1,\n",
        "                               test_neg_ratio=1)\n",
        "\n",
        "train_pos, train_neg = sampler.training_graphs\n",
        "test_pos, test_neg = sampler.test_graphs"
      ],
      "metadata": {
        "id": "ib9tMN65QxIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv\n",
        "import torch.nn as nn\n",
        "\n",
        "class ImprovedGraphSAGE(nn.Module):\n",
        "  def __init__(self, in_feats, h_feats, out_feats, dropout=0.5):\n",
        "        super(ImprovedGraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
        "        self.conv2 = SAGEConv(h_feats, out_feats, \"mean\")\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "import dgl.function as fn\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
        "            return g.edata[\"score\"][:, 0]"
      ],
      "metadata": {
        "id": "TzIhEJdJUCK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import dgl\n",
        "\n",
        "def train_model(model,\n",
        "                pred,\n",
        "                dataloader,\n",
        "                epochs,\n",
        "                lr=0.01):\n",
        "\n",
        "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(),\n",
        "                                                 pred.parameters()),\n",
        "                                                 lr=lr)\n",
        "\n",
        "    all_losses = []\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            batch_graph = batch[\"graph\"]    # گراف اصلی\n",
        "            pos_graph = batch[\"pos_graph\"]  # گراف مثبت\n",
        "            neg_graph = batch[\"neg_graph\"]  # گراف منفی\n",
        "\n",
        "            # Forward pass\n",
        "            h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "            pos_score = pred(pos_graph, h)\n",
        "            neg_score = pred(neg_graph, h)\n",
        "            loss = compute_loss(pos_score,neg_score)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            e = epoch\n",
        "            loss = epoch_loss\n",
        "\n",
        "        all_losses.append(epoch_loss)\n",
        "\n",
        "    print(f\"\\nEpoch: {e}, Loss: {loss:.4f}\")\n",
        "    return h, all_losses\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)"
      ],
      "metadata": {
        "id": "RG5q7F62ULlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import average_precision_score\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "class GraphEvaluator:\n",
        "    def __init__(self, metrics, pred, test_pos_g, test_neg_g, h, dataset_name, k=10):\n",
        "        self.metrics = metrics\n",
        "        self.dataset_name = dataset_name\n",
        "        self.k = k\n",
        "        self.__evaluate(pred, test_pos_g, test_neg_g, h)\n",
        "\n",
        "    def compute_metrics(self, pos_score, neg_score):\n",
        "        pos_array = pos_score.cpu().detach().numpy()\n",
        "        neg_array = neg_score.cpu().detach().numpy()\n",
        "        labels_pr = np.concatenate([np.ones_like(pos_array), np.zeros_like(neg_array)])\n",
        "        scores_pr = np.concatenate([pos_array, neg_array])\n",
        "        auc_pr = average_precision_score(labels_pr, scores_pr)\n",
        "\n",
        "        ranks = []\n",
        "        hits_at_k = []\n",
        "        for pos, neg in zip(pos_score, neg_score):\n",
        "            neg = neg.view(-1)\n",
        "            pos = pos.view(-1)\n",
        "            all_scores = torch.cat([neg, pos])\n",
        "            sorted_scores, indices = torch.sort(all_scores, descending=True)\n",
        "            rank = (indices == len(neg)).nonzero(as_tuple=True)[0].item() + 1\n",
        "            ranks.append(rank)\n",
        "            hits_at_k.append(1 if rank <= self.k else 0)\n",
        "\n",
        "        mrr = np.mean([1.0 / rank for rank in ranks])\n",
        "        hit_at_k = np.mean(hits_at_k)\n",
        "        loss = F.binary_cross_entropy_with_logits(torch.cat([pos_score, neg_score]),\n",
        "                                                  torch.cat([torch.ones(pos_score.shape[0]),\n",
        "                                                             torch.zeros(neg_score.shape[0])]))\n",
        "\n",
        "        return {\"AUC-PR\": auc_pr, \"MRR\": mrr, f\"Hit@{self.k}\": hit_at_k, \"Loss\": loss.item()}\n",
        "\n",
        "    def display_metrics(self):\n",
        "        '''نمایش دیکشنری metrics در قالب جدول'''\n",
        "        table = PrettyTable()\n",
        "        table.field_names = [\"Dataset\"] + list(next(iter(self.metrics.values())).keys())\n",
        "\n",
        "        for dataset, metrics in self.metrics.items():\n",
        "            row = [dataset] + list(metrics.values())\n",
        "            table.add_row(row)\n",
        "\n",
        "        print(table)\n",
        "\n",
        "    def __evaluate(self, pred, test_pos_g, test_neg_g, h):\n",
        "        '''ارزیابی مدل و نمایش نتایج (تابع خصوصی)'''\n",
        "        with torch.no_grad():\n",
        "            pos_score = pred(test_pos_g, h)\n",
        "            neg_score = pred(test_neg_g, h)\n",
        "            new_metrics = self.compute_metrics(pos_score, neg_score)\n",
        "            self.metrics[self.dataset_name] = new_metrics\n",
        "\n",
        "        # نمایش نتایج در قالب جدول\n",
        "        self.display_metrics()"
      ],
      "metadata": {
        "id": "r-MvesGSUT1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link Prediction With GraphSAGE + Dot Predictor**"
      ],
      "metadata": {
        "id": "bq8EHus7HT-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Imports =======\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from tabulate import tabulate\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "from sklearn import metrics\n",
        "\n",
        "# ==== Hyperparameters ====\n",
        "h_feats = 16\n",
        "out_feats = 10\n",
        "dropout = 0.5\n",
        "epochs = 2000\n",
        "lr = 0.01\n",
        "k = 10\n",
        "train_neg_ratio = 2\n",
        "test_neg_ratio = 1\n",
        "result = {'DataSet': 'Persian_LP'}\n",
        "\n",
        "# ==== Step 1: Dataset Preparation ====\n",
        "graphs = PersianDGLDataset(train_file=ILP_dataset_paths['PersianILP_V1']['train'],\n",
        "                           test_file =ILP_dataset_paths['PersianILP_V1']['test'])\n",
        "\n",
        "sampler = GraphNegativeSampler(\n",
        "    graphs['train'], graphs['test'],\n",
        "    train_neg_ratio=train_neg_ratio,\n",
        "    test_neg_ratio=test_neg_ratio\n",
        ")\n",
        "train_pos_g, train_neg_g = sampler.training_graphs\n",
        "test_pos_g,  test_neg_g  = sampler.test_graphs\n",
        "\n",
        "train_dataset = GraphBatchDataset([graphs['train']], [train_pos_g], [train_neg_g])\n",
        "train_loader  = GraphDataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "test_dataset = GraphBatchDataset([graphs['test']], [test_pos_g], [test_neg_g])\n",
        "test_loader  = GraphDataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "# ==== Step 2: Training ====\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([\n",
        "        torch.ones(pos_score.shape[0]),\n",
        "        torch.zeros(neg_score.shape[0])\n",
        "    ])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "feats = graphs[\"train\"].ndata[\"feat\"].shape[1]\n",
        "model = ImprovedGraphSAGE(\n",
        "    in_feats=feats,\n",
        "    h_feats=h_feats,\n",
        "    out_feats=out_feats,\n",
        "    dropout=dropout\n",
        ")\n",
        "pred = DotPredictor()\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()),\n",
        "    lr=lr\n",
        ")\n",
        "\n",
        "all_losses = []\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    epoch_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        batch_graph = batch[\"graph\"]\n",
        "        pos_graph   = batch[\"pos_graph\"]\n",
        "        neg_graph   = batch[\"neg_graph\"]\n",
        "\n",
        "        # Forward\n",
        "        h          = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_score  = pred(pos_graph, h)\n",
        "        neg_score  = pred(neg_graph, h)\n",
        "        loss       = compute_loss(pos_score, neg_score)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    all_losses.append(epoch_loss)\n",
        "\n",
        "# ==== Step3: Testing =====\n",
        "pos_scores = []\n",
        "pos_labels = []\n",
        "neg_scores = []\n",
        "neg_labels = []\n",
        "\n",
        "hit1_list = []\n",
        "hit3_list = []\n",
        "hit10_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    ranks = []\n",
        "    for b_idx, batch in enumerate(test_loader):\n",
        "\n",
        "        batch_graph = batch['graph']\n",
        "        pos_graph   = batch['pos_graph']\n",
        "        neg_graph   = batch['neg_graph']\n",
        "\n",
        "        # محاسبه امتیازهای مثبت و منفی\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        score_pos = pred(pos_graph, h)  # خروجی shape: (batch_size, 1)\n",
        "        score_neg = pred(neg_graph, h)  # خروجی shape: (batch_size, 1)\n",
        "\n",
        "        # افزودن به لیست‌ها\n",
        "        pos_scores += score_pos.squeeze().detach().cpu().tolist()\n",
        "        neg_scores += score_neg.squeeze().detach().cpu().tolist()\n",
        "\n",
        "        # برچسب‌ها\n",
        "        targets_pos = torch.ones(len(score_pos))\n",
        "        targets_neg = torch.zeros(len(score_neg))\n",
        "        pos_labels += targets_pos.detach().cpu().tolist()\n",
        "        neg_labels += targets_neg.detach().cpu().tolist()\n",
        "\n",
        "        # ساخت ماتریس امتیاز برای softmax و محاسبه رتبه\n",
        "        score_pos = score_pos.view(-1, 1)\n",
        "        score_neg = score_neg.view(-1, 1)\n",
        "        scores = torch.cat([score_pos, score_neg], dim=1)  # فرض بر اینکه هر دو [batch_size, 1] باشند\n",
        "        scores = torch.softmax(scores, dim=1)\n",
        "        scores = scores.detach().cpu().numpy()\n",
        "\n",
        "        rank = np.argwhere(np.argsort(scores, axis=1)[:, ::-1] == 0)[:, 1] + 1\n",
        "        ranks += rank.tolist()\n",
        "\n",
        "        # محاسبه Hit@K\n",
        "        hit1 = [1 if item <= 1 else 0 for item in rank]\n",
        "        hit3 = [1 if item <= 3 else 0 for item in rank]\n",
        "        hit10 = [1 if item <= 10 else 0 for item in rank]\n",
        "        hit1_list += hit1\n",
        "        hit3_list += hit3\n",
        "        hit10_list += hit10\n",
        "\n",
        "result = {}\n",
        "result[\"Dataset\"] = \"Persian_LP\"\n",
        "result[\"AUC\"] = metrics.roc_auc_score(pos_labels + neg_labels, pos_scores + neg_scores)\n",
        "result[\"AUC_PR\"] = metrics.average_precision_score(pos_labels + neg_labels, pos_scores + neg_scores)\n",
        "result[\"MRR\"] = np.mean(1.0 / np.array(ranks)).item()\n",
        "result[\"Hit1\"] = np.mean(hit1_list)\n",
        "result[\"Hit3\"] = np.mean(hit3_list)\n",
        "result[\"Hit10\"] = np.mean(hit10_list)\n",
        "print(result)\n",
        "\n",
        "headers = ['Dataset', 'AUC' ,'AUC_PR', 'MRR', 'Hit1', 'Hit3', 'Hit10']\n",
        "values  = [[result[key] for key in headers]]\n",
        "print(\"\\n\" + tabulate(\n",
        "    values,\n",
        "    headers=headers,\n",
        "    tablefmt=\"fancy_grid\",\n",
        "    floatfmt=\".4f\",\n",
        "    stralign=\"center\",\n",
        "    numalign=\"left\"))"
      ],
      "metadata": {
        "id": "GeiPLUKEc3RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Imports =======\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from tabulate import tabulate\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "\n",
        "# ======== Hyperparameters =======\n",
        "h_feats = 32\n",
        "out_feats = 16\n",
        "dropout = 0.5\n",
        "epochs = 2000\n",
        "lr = 0.01\n",
        "k = 10\n",
        "train_neg_ratio = 1\n",
        "test_neg_ratio = 1\n",
        "\n",
        "# ======== Dataset Preparation =======\n",
        "graphs = PersianDGLDataset(\n",
        "    train_file=ILP_dataset_paths['WN18RR_v1_ind']['train'],\n",
        "    test_file=ILP_dataset_paths['WN18RR_v1_ind']['test'])\n",
        "\n",
        "sampler = GraphNegativeSampler(\n",
        "    graphs['train'], graphs['test'],\n",
        "    train_neg_ratio=train_neg_ratio,\n",
        "    test_neg_ratio=test_neg_ratio)\n",
        "\n",
        "train_pos_g, train_neg_g = sampler.training_graphs\n",
        "test_pos_g, test_neg_g = sampler.test_graphs\n",
        "\n",
        "\n",
        "train_dataset = GraphBatchDataset([graphs['train']], [train_pos_g], [train_neg_g])\n",
        "train_loader = GraphDataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "test_dataset = GraphBatchDataset([graphs['test']], [test_pos_g], [test_neg_g])\n",
        "test_loader = GraphDataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "# ======== Model Initialization =======\n",
        "feats = graphs[\"train\"].ndata[\"feat\"].shape[1]\n",
        "model = ImprovedGraphSAGE(\n",
        "    in_feats=feats,\n",
        "    h_feats=h_feats,\n",
        "    out_feats=out_feats,\n",
        "    dropout=dropout)\n",
        "\n",
        "pred = DotPredictor()\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()),\n",
        "    lr=lr\n",
        ")\n",
        "\n",
        "# ======== Training Function =======\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([\n",
        "        torch.ones(pos_score.shape[0]),\n",
        "        torch.zeros(neg_score.shape[0])\n",
        "    ])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "# ======== Training Loop =======\n",
        "all_losses = []\n",
        "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch_graph = batch[\"graph\"]\n",
        "        pos_graph = batch[\"pos_graph\"]\n",
        "        neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "        # Forward pass\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_score = pred(pos_graph, h)\n",
        "        neg_score = pred(neg_graph, h)\n",
        "        loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    all_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "# ======== Evaluation =======\n",
        "@torch.no_grad()\n",
        "def prediction_model(model, test_loader):\n",
        "    model.eval()\n",
        "    logits = []\n",
        "    labels = []\n",
        "    indexes = []\n",
        "\n",
        "    query_id = 0\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        batch_graph = batch['graph']\n",
        "        pos_graph = batch['pos_graph']\n",
        "        neg_graph = batch['neg_graph']\n",
        "\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_scores = pred(pos_graph, h)\n",
        "        neg_scores = pred(neg_graph, h)\n",
        "\n",
        "        for pos_score in pos_scores:\n",
        "            # هر نمونه‌ی مثبت یک query است\n",
        "            all_scores = torch.cat([pos_score.unsqueeze(0), neg_scores])\n",
        "            all_labels = torch.cat([\n",
        "                torch.ones(1, dtype=torch.bool),\n",
        "                torch.zeros(neg_scores.shape[0], dtype=torch.bool)])\n",
        "            all_indexes = torch.full((all_scores.shape[0],), query_id, dtype=torch.long)\n",
        "\n",
        "            logits.append(all_scores)\n",
        "            labels.append(all_labels)\n",
        "            indexes.append(all_indexes)\n",
        "\n",
        "            query_id += 1\n",
        "\n",
        "    logits = torch.cat(logits, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "    indexes = torch.cat(indexes, dim=0)\n",
        "    return logits, labels, indexes\n",
        "\n",
        "# Get predictions\n",
        "logits, labels, indexes = prediction_model(model, test_loader)\n",
        "\n",
        "# Compute metrics\n",
        "auc = roc_auc_score(labels.numpy(), logits.numpy())\n",
        "auc_pr = average_precision_score(labels.numpy(), logits.numpy())\n",
        "\n",
        "# Initialize metrics\n",
        "mrr_metric = RetrievalMRR()\n",
        "hit_rate_metric = RetrievalHitRate(top_k=10)\n",
        "\n",
        "# Update metrics with all predictions\n",
        "mrr_metric.update(logits, labels, indexes)\n",
        "hit_rate_metric.update(logits, labels, indexes)\n",
        "\n",
        "# Compute final metrics\n",
        "mrr = mrr_metric.compute().item()\n",
        "hit_at_k = hit_rate_metric.compute().item()\n",
        "\n",
        "# Compute loss\n",
        "loss = F.binary_cross_entropy_with_logits(logits, labels.float()).item()\n",
        "\n",
        "# Store results\n",
        "dataset_name = 'WN18RR_v1_ind'\n",
        "result_dict = {\n",
        "    dataset_name: {\n",
        "        \"AUC\": auc,\n",
        "        \"AUC_PR\": auc_pr,\n",
        "        \"MRR\": mrr,\n",
        "        \"HIT_at_K\": hit_at_k,\n",
        "        \"LOSS\": loss\n",
        "    }\n",
        "}\n",
        "\n",
        "# ======== Display Results =======\n",
        "headers = ['DataSet', 'AUC', 'AUC_PR', 'MRR', 'HIT_at_K', 'LOSS']\n",
        "table_data = [[\n",
        "    dataset_name,\n",
        "    result_dict[dataset_name]['AUC'],\n",
        "    result_dict[dataset_name]['AUC_PR'],\n",
        "    result_dict[dataset_name]['MRR'],\n",
        "    result_dict[dataset_name]['HIT_at_K'],\n",
        "    result_dict[dataset_name]['LOSS']\n",
        "]]\n",
        "\n",
        "print(\"\\nنتایج نهایی آزمایش:\")\n",
        "print(tabulate(\n",
        "    table_data,\n",
        "    headers=headers,\n",
        "    tablefmt=\"fancy_grid\",\n",
        "    floatfmt=\".4f\",\n",
        "    stralign=\"center\",\n",
        "    numalign=\"left\"))\n",
        "\n",
        "# ======== Save Model =======\n",
        "torch.save(model.state_dict(), f'model_{dataset_name}.pth')"
      ],
      "metadata": {
        "id": "64PrZkgIUWuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Imports =======\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from tabulate import tabulate\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "\n",
        "# ======== Hyperparameters =======\n",
        "h_feats = 64\n",
        "out_feats = 16\n",
        "dropout = 0.5\n",
        "epochs = 2000\n",
        "lr = 0.001\n",
        "k = 10\n",
        "train_neg_ratio = 1\n",
        "test_neg_ratio = 50\n",
        "\n",
        "# ======== Dataset Preparation =======\n",
        "graphs = PersianDGLDataset(\n",
        "    train_file=ILP_dataset_paths['WN18RR_v1_ind']['train'],\n",
        "    test_file=ILP_dataset_paths['WN18RR_v1_ind']['test']\n",
        ")\n",
        "\n",
        "sampler = GraphNegativeSampler(\n",
        "    graphs['train'], graphs['test'],\n",
        "    train_neg_ratio=train_neg_ratio,\n",
        "    test_neg_ratio=test_neg_ratio)\n",
        "\n",
        "train_pos_g, train_neg_g = sampler.training_graphs\n",
        "test_pos_g, test_neg_g = sampler.test_graphs\n",
        "\n",
        "\n",
        "train_dataset = GraphBatchDataset([graphs['train']], [train_pos_g], [train_neg_g])\n",
        "train_loader = GraphDataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "test_dataset = GraphBatchDataset([graphs['test']], [test_pos_g], [test_neg_g])\n",
        "test_loader = GraphDataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "# ======== Model Initialization =======\n",
        "feats = graphs[\"train\"].ndata[\"feat\"].shape[1]\n",
        "model = ImprovedGraphSAGE(\n",
        "    in_feats=feats,\n",
        "    h_feats=h_feats,\n",
        "    out_feats=out_feats,\n",
        "    dropout=dropout\n",
        ")\n",
        "pred = DotPredictor()\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()),\n",
        "    lr=lr\n",
        ")\n",
        "\n",
        "# ======== Training Function =======\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([\n",
        "        torch.ones(pos_score.shape[0]),\n",
        "        torch.zeros(neg_score.shape[0])\n",
        "    ])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "# ======== Training Loop =======\n",
        "all_losses = []\n",
        "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch_graph = batch[\"graph\"]\n",
        "        pos_graph = batch[\"pos_graph\"]\n",
        "        neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "        # Forward pass\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_score = pred(pos_graph, h)\n",
        "        neg_score = pred(neg_graph, h)\n",
        "        loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    all_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "# ======== Evaluation =======\n",
        "@torch.no_grad()\n",
        "def prediction_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_pos_scores = []\n",
        "    all_neg_scores = []\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        batch_graph = batch['graph']\n",
        "        pos_graph = batch['pos_graph']\n",
        "        neg_graph = batch['neg_graph']\n",
        "\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_scores = pred(pos_graph, h)\n",
        "        neg_scores = pred(neg_graph, h)\n",
        "\n",
        "        all_pos_scores.append(pos_scores.cpu())\n",
        "        all_neg_scores.append(neg_scores.cpu())\n",
        "\n",
        "    return all_pos_scores, all_neg_scores\n",
        "\n",
        "def calculate_mrr(pos_scores, neg_scores):\n",
        "    reciprocal_ranks = []\n",
        "\n",
        "    for pos_batch, neg_batch in zip(pos_scores, neg_scores):\n",
        "        for pos_score in pos_batch:\n",
        "\n",
        "            combined_scores = torch.cat([neg_batch, pos_score.unsqueeze(0)])\n",
        "            sorted_scores, indices = torch.sort(combined_scores, descending=True)\n",
        "            pos_index = len(combined_scores) - 1  # چون نمره‌ی مثبت در انتها اضافه شده\n",
        "            rank = (indices == pos_index).nonzero(as_tuple=True)[0].item() + 1\n",
        "            reciprocal_ranks.append(1.0 / rank)\n",
        "\n",
        "    return np.mean(reciprocal_ranks) if reciprocal_ranks else 0.0\n",
        "\n",
        "def calculate_hit_at_k(pos_scores, neg_scores, k=10):\n",
        "    hits = 0\n",
        "    total = 0\n",
        "\n",
        "    for pos_batch, neg_batch in zip(pos_scores, neg_scores):\n",
        "        for pos_score in pos_batch:\n",
        "            # ترکیب نمره‌ی مثبت با نمرات منفی\n",
        "            combined_scores = torch.cat([neg_batch, pos_score.unsqueeze(0)])\n",
        "\n",
        "            # مرتب‌سازی نزولی نمرات\n",
        "            sorted_scores, indices = torch.sort(combined_scores, descending=True)\n",
        "\n",
        "            # موقعیت نمره‌ی مثبت در لیست مرتب‌شده\n",
        "            pos_index = len(combined_scores) - 1  # چون نمره‌ی مثبت در انتها اضافه شده\n",
        "            rank = (indices == pos_index).nonzero(as_tuple=True)[0].item() + 1\n",
        "\n",
        "            # بررسی اینکه آیا رتبه در بین K برتر قرار دارد\n",
        "            if rank <= k:\n",
        "                hits += 1\n",
        "            total += 1\n",
        "\n",
        "    return hits / total if total else 0.0\n",
        "\n",
        "# محاسبه متریک‌ها\n",
        "all_pos_scores, all_neg_scores = prediction_model(model, test_loader)\n",
        "mrr = calculate_mrr(all_pos_scores, all_neg_scores)\n",
        "hit_at_k = calculate_hit_at_k(all_pos_scores, all_neg_scores, k=k)\n",
        "\n",
        "# محاسبه سایر متریک‌ها\n",
        "all_labels = np.concatenate([\n",
        "    np.ones(sum(len(x) for x in all_pos_scores)),\n",
        "    np.zeros(sum(len(x) for x in all_neg_scores))\n",
        "])\n",
        "all_scores = np.concatenate([\n",
        "    torch.cat(all_pos_scores).numpy(),\n",
        "    torch.cat(all_neg_scores).numpy()\n",
        "])\n",
        "\n",
        "auc = roc_auc_score(all_labels, all_scores)\n",
        "auc_pr = average_precision_score(all_labels, all_scores)\n",
        "loss = F.binary_cross_entropy_with_logits(torch.cat(all_pos_scores + all_neg_scores),\n",
        "                                         torch.Tensor(all_labels)).item()\n",
        "\n",
        "\n",
        "\n",
        "# نمایش نتایج\n",
        "results = {\n",
        "    'AUC': auc,\n",
        "    'AUC_PR': auc_pr,\n",
        "    'MRR': mrr,\n",
        "    'HIT_at_K': hit_at_k,\n",
        "    'LOSS': loss}\n",
        "print('\\n', results)"
      ],
      "metadata": {
        "id": "EM-eW1RyH3K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import tensor\n",
        "from torchmetrics.retrieval import RetrievalMRR\n",
        "# logits, labels, indexes\n",
        "\n",
        "# indexes = tensor([0, 0, 0, 1, 1, 1, 1])\n",
        "# preds = tensor([0.2, 0.3, 0.5, 0.1, 0.3, 0.5, 0.2])\n",
        "# target = tensor([False, False, True, False, True, False, True])\n",
        "mrr = RetrievalMRR()\n",
        "print(f'logits: {logits.shape} , {logits}')\n",
        "print(f'labels: {labels.shape} , {labels}')\n",
        "print(f'indexes:{indexes.shape} , {indexes}')\n",
        "mrr(logits, labels, indexes=indexes)\n"
      ],
      "metadata": {
        "id": "8CgO_RPxanNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_mrr(args, model, node_emb, seeds, labels, indexes):\n",
        "    \"\"\"Compute the Mean Reciprocal Rank (MRR) for given source and destination\n",
        "    nodes.\n",
        "\n",
        "    This function computes the MRR for a set of node pairs, dividing the task\n",
        "    into batches to handle potentially large graphs.\n",
        "    \"\"\"\n",
        "\n",
        "    preds = torch.empty(seeds.shape[0], device=indexes.device)\n",
        "    mrr = RetrievalMRR()\n",
        "    seeds_src, seeds_dst = seeds.T\n",
        "    # The constant number is 1001, due to negtive ratio in the `ogbl-citation2`\n",
        "    # dataset is 1000.\n",
        "    eval_size = args.eval_batch_size * 1001\n",
        "    # Loop over node pairs in batches.\n",
        "    for start in tqdm.trange(0, seeds_src.shape[0], eval_size, desc=\"Evaluate\"):\n",
        "        end = min(start + eval_size, seeds_src.shape[0])\n",
        "\n",
        "        # Fetch embeddings for current batch of source and destination nodes.\n",
        "        h_src = node_emb[seeds_src[start:end]].to(args.device)\n",
        "        h_dst = node_emb[seeds_dst[start:end]].to(args.device)\n",
        "\n",
        "        # Compute prediction scores using the model.\n",
        "        pred = model.predictor(h_src * h_dst).squeeze()\n",
        "        preds[start:end] = pred\n",
        "    return mrr(preds, labels, indexes=indexes)"
      ],
      "metadata": {
        "id": "yaC7oi0-L_F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import average_precision_score\n",
        "from tabulate import tabulate\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "\n",
        "def train_and_evaluate_link_prediction(\n",
        "    train_file,\n",
        "    test_file,\n",
        "    h_feats=16,\n",
        "    out_feats=10,\n",
        "    dropout=0.5,\n",
        "    epochs=2000,\n",
        "    lr=0.01,\n",
        "    k=10,\n",
        "    train_neg_ratio=1,\n",
        "    test_neg_ratio=10,\n",
        "    dataset_name='PersianILP_V1',\n",
        "    save_model=True):\n",
        "\n",
        "    # ======== آماده‌سازی داده‌ها ========\n",
        "    graphs = PersianDGLDataset(train_file=train_file, test_file=test_file)\n",
        "    sampler = GraphNegativeSampler(\n",
        "        graphs['train'], graphs['test'],\n",
        "        train_neg_ratio=train_neg_ratio,\n",
        "        test_neg_ratio=test_neg_ratio)\n",
        "\n",
        "    train_pos_g, train_neg_g = sampler.training_graphs\n",
        "    test_pos_g, test_neg_g = sampler.test_graphs\n",
        "\n",
        "    train_dataset = GraphBatchDataset([graphs['train']], [train_pos_g], [train_neg_g])\n",
        "    train_loader = GraphDataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "    test_dataset = GraphBatchDataset([graphs['test']], [test_pos_g], [test_neg_g])\n",
        "    test_loader = GraphDataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "    # ======== مدل و بهینه‌ساز ========\n",
        "    feats = graphs[\"train\"].ndata[\"feat\"].shape[1]\n",
        "    model = ImprovedGraphSAGE(\n",
        "        in_feats=feats,\n",
        "        h_feats=h_feats,\n",
        "        out_feats=out_feats,\n",
        "        dropout=dropout\n",
        "    )\n",
        "    pred = DotPredictor()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        itertools.chain(model.parameters(), pred.parameters()),\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    # ======== آموزش ========\n",
        "    def compute_loss(pos_score, neg_score):\n",
        "        scores = torch.cat([pos_score, neg_score])\n",
        "        labels = torch.cat([\n",
        "            torch.ones(pos_score.shape[0]),\n",
        "            torch.zeros(neg_score.shape[0])\n",
        "        ])\n",
        "        return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "    all_losses = []\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            batch_graph = batch[\"graph\"]\n",
        "            pos_graph = batch[\"pos_graph\"]\n",
        "            neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "            h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "            pos_score = pred(pos_graph, h)\n",
        "            neg_score = pred(neg_graph, h)\n",
        "            loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        all_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "    # ======== ارزیابی ========\n",
        "    model.eval()\n",
        "    result_dict = {dataset_name: {}}\n",
        "\n",
        "    mrr_metric = RetrievalMRR()\n",
        "    hit_rate_metric = RetrievalHitRate(top_k=k)\n",
        "    all_pos_scores = []\n",
        "    all_neg_scores = []\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        batch_graph = batch['graph']\n",
        "        pos_graph = batch['pos_graph']\n",
        "        neg_graph = batch['neg_graph']\n",
        "\n",
        "        with torch.no_grad():\n",
        "            h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "            pos_scores = pred(pos_graph, h)\n",
        "            neg_scores = pred(neg_graph, h)\n",
        "\n",
        "            logits = torch.cat([pos_scores, neg_scores])\n",
        "            labels = torch.cat([\n",
        "                torch.ones(pos_scores.shape[0], dtype=torch.int),\n",
        "                torch.zeros(neg_scores.shape[0], dtype=torch.int)\n",
        "            ])\n",
        "            indexes = torch.cat([\n",
        "                torch.arange(pos_scores.shape[0]),\n",
        "                torch.arange(neg_scores.shape[0])\n",
        "            ])\n",
        "\n",
        "            mrr_metric.update(logits, labels, indexes)\n",
        "            hit_rate_metric.update(logits, labels, indexes)\n",
        "\n",
        "            all_pos_scores.append(pos_scores.cpu().numpy())\n",
        "            all_neg_scores.append(neg_scores.cpu().numpy())\n",
        "\n",
        "            result_dict[dataset_name]['LOSS'] = F.binary_cross_entropy_with_logits(\n",
        "                logits, labels.float()).item()\n",
        "\n",
        "    # محاسبه معیارهای نهایی\n",
        "    result_dict[dataset_name]['MRR'] = mrr_metric.compute().item()\n",
        "    result_dict[dataset_name]['HIT_at_K'] = hit_rate_metric.compute().item()\n",
        "\n",
        "    labels_pr = np.concatenate([\n",
        "        np.ones(sum(len(x) for x in all_pos_scores)),\n",
        "        np.zeros(sum(len(x) for x in all_neg_scores))\n",
        "    ])\n",
        "    scores_pr = np.concatenate([\n",
        "        np.concatenate(all_pos_scores),\n",
        "        np.concatenate(all_neg_scores)\n",
        "    ])\n",
        "    result_dict[dataset_name]['AUC_PR'] = average_precision_score(labels_pr, scores_pr)\n",
        "\n",
        "    # ======== نمایش نتایج ========\n",
        "    clear_output()\n",
        "    headers = ['DataSet', 'AUC_PR', 'MRR', 'HIT_at_K', 'LOSS']\n",
        "    table_data = [[\n",
        "        dataset_name,\n",
        "        result_dict[dataset_name]['AUC_PR'],\n",
        "        result_dict[dataset_name]['MRR'],\n",
        "        result_dict[dataset_name]['HIT_at_K'],\n",
        "        result_dict[dataset_name]['LOSS']\n",
        "    ]]\n",
        "\n",
        "    print(\"\\nنتایج نهایی آزمایش:\")\n",
        "    print(tabulate(\n",
        "        table_data,\n",
        "        headers=headers,\n",
        "        tablefmt=\"fancy_grid\",\n",
        "        floatfmt=\".4f\",\n",
        "        stralign=\"center\",\n",
        "        numalign=\"left\"\n",
        "    ))\n",
        "\n",
        "    # ======== ذخیره مدل ========\n",
        "    if save_model:\n",
        "        torch.save(model.state_dict(), f'model_{dataset_name}.pth')\n",
        "        print(f\"\\nمدل در 'model_{dataset_name}.pth' ذخیره شد.\")\n",
        "\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "q21qBJ85TsRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSnXtf221Rcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate_link_prediction(\n",
        "    ILP_dataset_paths['WN18RR_v1_ind']['train'],\n",
        "    ILP_dataset_paths['WN18RR_v1_ind']['test'],\n",
        "    h_feats=16,\n",
        "    out_feats=10,\n",
        "    dropout=0.5,\n",
        "    epochs=100,\n",
        "    lr=0.01,\n",
        "    k=10,\n",
        "    train_neg_ratio=1,\n",
        "    test_neg_ratio=10,\n",
        "    dataset_name='PersianILP_V1',\n",
        "    save_model=True)"
      ],
      "metadata": {
        "id": "9Aq6elSCz6B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for key, value in ILP_dataset_paths.items():\n",
        "  results = run_Inductive_link_prediction_experiment( train_file = value['train'],\n",
        "                                                      test_file  = value['test'],\n",
        "                                                      dataset_name = key,\n",
        "                                                      result_dict = results)\n",
        "  print(key, value['train'])\n",
        "  print_final_results(results)"
      ],
      "metadata": {
        "id": "vCDN0BufT1bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link Prediction With GraphSAGE + TransE**"
      ],
      "metadata": {
        "id": "KGn3o3FdB356"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.nn import SAGEConv, TransE\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# Step 0: Hyperparameter Setting\n",
        "result = {}\n",
        "epoch = 50\n",
        "result['Dataset'] = 'Persian_LP'\n",
        "\n",
        "# Step 1: Load Data\n",
        "# kg = PersianDGLDataset('/content/FarsiBase/triple.csv')\n",
        "train_file = '/content/Data_InductiveLinkPrediction/WN18RR_v1_ind/train.txt'\n",
        "test_file =  '/content/Data_InductiveLinkPrediction/WN18RR_v1_ind/test.txt'\n",
        "kg = PersianDGLDataset(train_file=train_file, test_file=test_file)\n",
        "\n",
        "train_graph = kg[\"train\"]\n",
        "test_graph = kg[\"test\"]\n",
        "feat_dim = kg[\"train\"].ndata[\"feat\"].shape[1]\n",
        "num_rels = kg[\"train\"].edata[\"e_type\"].shape[0]\n",
        "\n",
        "# Step 2: Generate Negative And Positive Graph And Batching Data\n",
        "sampler = GraphNegativeSampler(\n",
        "    graphs['train'], graphs['test'],\n",
        "    train_neg_ratio=train_neg_ratio,\n",
        "    test_neg_ratio=test_neg_ratio\n",
        ")\n",
        "train_pos_g, train_neg_g = sampler.training_graphs\n",
        "test_pos_g,  test_neg_g  = sampler.test_graphs\n",
        "train_dataset = GraphBatchDataset([kg['train']], [train_pos_g], [train_neg_g])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "test_dataset = GraphBatchDataset([kg['test']], [test_pos_g], [test_neg_g])\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "# Step 3: Model Definition And Optimization\n",
        "sage_model = ImprovedGraphSAGE(in_feats=feat_dim, h_feats=64, out_feats=64)\n",
        "transe_scorer = TransE(num_rels=num_rels, feats=64)\n",
        "optimizer = torch.optim.Adam(list(sage_model.parameters()) + list(transe_scorer.parameters()), lr=0.01)\n",
        "\n",
        "# Step 4: Loss Function\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "# Step 5: Training Phase\n",
        "for epoch in tqdm(range(epoch)):\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        batch_graph = batch[\"graph\"]\n",
        "        pos_graph = batch[\"pos_graph\"]\n",
        "        neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "        # Forward\n",
        "        sage_model.train()\n",
        "        h = sage_model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_src, pos_dst = pos_graph.edges()\n",
        "        neg_src, neg_dst = neg_graph.edges()\n",
        "        pos_rels = pos_graph.edata[\"e_type\"]\n",
        "        neg_rels = neg_graph.edata[\"e_type\"]\n",
        "        pos_score = transe_scorer(h[pos_src], h[pos_dst], pos_rels)\n",
        "        neg_score = transe_scorer(h[neg_src], h[neg_dst], neg_rels)\n",
        "        loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        # print(f\"📘 Epoch {epoch+1} | Loss: {total_loss:.4f}\") if (epoch + 1) % 10 == 0 else None\n",
        "result[\"LOSS\"] = round(total_loss, 4)\n",
        "\n",
        "# Step 6: Evaluating Phase\n",
        "for batch in test_dataloader:\n",
        "    test_batch_graph = batch[\"graph\"]\n",
        "    test_pos_graph = batch[\"pos_graph\"]\n",
        "    test_neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "    sage_model.eval()\n",
        "    transe_scorer.eval()\n",
        "    with torch.no_grad():\n",
        "        # Calculate AUC-PR Metric\n",
        "        h = sage_model(test_batch_graph, test_batch_graph.ndata[\"feat\"])\n",
        "        pos_src, pos_dst = test_pos_graph.edges()\n",
        "        neg_src, neg_dst = test_neg_graph.edges()\n",
        "        pos_rels = test_pos_graph.edata[\"e_type\"]\n",
        "        neg_rels = test_neg_graph.edata[\"e_type\"]\n",
        "        pos_score = transe_scorer(h[pos_src], h[pos_dst], pos_rels)\n",
        "        neg_score = transe_scorer(h[neg_src], h[neg_dst], neg_rels)\n",
        "        all_scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
        "        all_labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
        "        auc_pr = average_precision_score(all_labels, all_scores)\n",
        "        result['AUC-PR'] = round(auc_pr, 4)\n",
        "\n",
        "# Step 7: Display Result\n",
        "from tabulate import tabulate\n",
        "headers = result.keys()\n",
        "values = [result.values()]\n",
        "print('\\n\\n',tabulate(values,\n",
        "                    headers=headers,\n",
        "                    tablefmt=\"grid\",\n",
        "                    floatfmt=\".4f\"))"
      ],
      "metadata": {
        "id": "VFjIgY3uaHNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}