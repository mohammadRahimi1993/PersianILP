{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "1DvjSVCDHmZz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!pip uninstall -y numpy\n",
        "!pip cache purge\n",
        "!pip install numpy==1.26.4\n",
        "clear_output()\n",
        "print(\"Numpy install successful!\")\n",
        "\n",
        "import os\n",
        "import IPython\n",
        "os._exit(0)"
      ],
      "metadata": {
        "id": "BuOya1ZL61rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/torch-2.2/repo.html\n",
        "!pip install torchmetrics==1.2.1 transformers==4.38.0\n",
        "!pip install torcheval\n",
        "!pip install scikit-learn\n",
        "!pip install deep-translator\n",
        "clear_output()\n",
        "\n",
        "import os\n",
        "import dgl\n",
        "import torch\n",
        "import torchmetrics\n",
        "import transformers\n",
        "import torcheval\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "os.environ['DGLBACKEND'] = \"pytorch\"\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "try:\n",
        "    import dgl\n",
        "    import dgl.graphbolt as gb\n",
        "    installed = True\n",
        "except ImportError as error:\n",
        "    installed = False\n",
        "    print(error)\n",
        "\n",
        "print(\"DGL installed!\" if installed else \"DGL not found!\")\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"TorchMetrics Version: \", torchmetrics.__version__)\n",
        "print(\"Transformers Version: \", transformers.__version__)\n",
        "print(\"DGL Version: \", dgl.__version__)\n",
        "print(\"TorchEval Is: \", torcheval.__version__)"
      ],
      "metadata": {
        "id": "Yg69giwm7IKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1- Create PersianILP"
      ],
      "metadata": {
        "id": "1DvjSVCDHmZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extrac Zip File**"
      ],
      "metadata": {
        "id": "ojMxG3fE7OaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/SPARQL.zip\"\n",
        "extract_path = \"/content/extracted_excels\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "excel_files = [os.path.join(extract_path, f) for f in os.listdir(extract_path) if f.endswith('.xlsx') or f.endswith('.xls')]\n",
        "merged_df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "30rp51NcVLy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Incomplete Triple**"
      ],
      "metadata": {
        "id": "TuoL5jzA7UmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡\n",
        "extract_path = \"/content/extracted_excels\"\n",
        "output_path = \"/content/FarsiBase\"\n",
        "os.makedirs(output_path, exist_ok=True)  # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯\n",
        "\n",
        "# ÛŒØ§ÙØªÙ† Ùˆ Ø§Ø¯ØºØ§Ù… ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV\n",
        "csv_files = [os.path.join(extract_path, f) for f in os.listdir(extract_path) if f.lower().endswith('.csv')]\n",
        "print(f\"ğŸ” ØªØ¹Ø¯Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV ÛŒØ§ÙØªâ€ŒØ´Ø¯Ù‡: {len(csv_files)}\")\n",
        "\n",
        "# Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø§Ø¯ØºØ§Ù… ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§\n",
        "merged_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
        "merged_df.to_csv('/content/mergeData', index=False, encoding='utf-8-sig')\n",
        "print(\"âœ… ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù†Ø¯.\\n\")\n",
        "\n",
        "# Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø§Ø² Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡\n",
        "print(\"ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡:\")\n",
        "print(\"=================================\")\n",
        "print(f\"â¡ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§: {len(merged_df):,}\")\n",
        "print(f\"â¡ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: {len(merged_df.columns)}\")\n",
        "print(\"\\nğŸ”¹ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‚Ø§Ø¯ÛŒØ± null Ø¯Ø± Ù‡Ø± Ø³ØªÙˆÙ†:\")\n",
        "print(merged_df.isnull().sum())\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ URI\n",
        "def simplify_uri(uri):\n",
        "    if isinstance(uri, str):\n",
        "        return uri.strip().split(\"/\")[-1].split(\"#\")[-1]  # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ù‡Ù†Ø¯Ù„ Ú©Ø±Ø¯Ù† URIÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n",
        "    return uri\n",
        "\n",
        "# Ø§Ø¹Ù…Ø§Ù„ Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø±ÙˆÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§\n",
        "cols_to_simplify = [\"subjectLabel\", \"predicateLabel\", \"objectLabel\"]\n",
        "simplified_df = merged_df.copy()\n",
        "for col in cols_to_simplify:\n",
        "    simplified_df[col] = simplified_df[col].apply(simplify_uri)\n",
        "\n",
        "#  Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ùˆ Ø®Ø§Ù„ÛŒ\n",
        "simplified_df.drop_duplicates(inplace=True)\n",
        "simplified_df = simplified_df.dropna(how='all')\n",
        "print(f\"\\nâ™» ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ: {len(simplified_df):,}\")\n",
        "\n",
        "# Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù¾Ø± Ø´Ø¯Ù‡\n",
        "simplified_df[\"filled_count\"] = simplified_df[cols_to_simplify].notna().sum(axis=1)\n",
        "\n",
        "# Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø§Ù…Ù„ Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "complete_df = simplified_df[simplified_df[\"filled_count\"] == 3].drop(columns=[\"filled_count\"])\n",
        "complete_path = os.path.join(output_path, \"complete_triples.csv\")\n",
        "complete_df.to_csv(complete_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"\\nğŸ’¾ ÙØ§ÛŒÙ„ triples Ú©Ø§Ù…Ù„ ({len(complete_df):,} Ø±Ø¯ÛŒÙ) Ø¯Ø± {complete_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
        "\n",
        "two_filled_df = simplified_df[simplified_df[\"filled_count\"] == 2].drop(columns=[\"filled_count\"])\n",
        "two_path = os.path.join(output_path, \"triples_with_two_values.csv\")\n",
        "two_filled_df.to_csv(two_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"ğŸ’¾ ÙØ§ÛŒÙ„ triples Ø¨Ø§ Ø¯Ùˆ Ù…Ù‚Ø¯Ø§Ø± ({len(two_filled_df):,} Ø±Ø¯ÛŒÙ) Ø¯Ø± {two_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
        "\n",
        "one_filled_df = simplified_df[simplified_df[\"filled_count\"] == 1].drop(columns=[\"filled_count\"])\n",
        "one_path = os.path.join(output_path, \"triples_with_one_value.csv\")\n",
        "one_filled_df.to_csv(one_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"ğŸ’¾ ÙØ§ÛŒÙ„ triples Ø¨Ø§ ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± ({len(one_filled_df):,} Ø±Ø¯ÛŒÙ) Ø¯Ø± {one_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
        "\n",
        "# Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "print(\"\\nğŸ‰ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!\")\n",
        "print(f\"\\nğŸ“ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ:\\n{simplified_df.count()}\")"
      ],
      "metadata": {
        "id": "BxgnSL28HR1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FarsiBase Data Cleaning**"
      ],
      "metadata": {
        "id": "32kahtRBEVCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def convert_persian_to_english(number):\n",
        "    persian_to_english = str.maketrans('Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹', '0123456789')\n",
        "    return str(number).translate(persian_to_english)\n",
        "\n",
        "df = pd.read_csv(\"/content/FarsiBase/complete_triples.csv\")\n",
        "for column in ['subjectLabel', 'predicateLabel', 'objectLabel']:\n",
        "    df[column] = df[column].apply(convert_persian_to_english)\n",
        "\n",
        "# Clean Relation\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^dcterms#subject','Ù…ÙˆØ¶ÙˆØ¹/Ù…Ø­ØªÙˆØ§', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^subject','Ù…ÙˆØ¶ÙˆØ¹', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^birth place','Ù…Ø­Ù„ ØªÙˆÙ„Ø¯', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^birth_place','Ù…Ø­Ù„ ØªÙˆÙ„Ø¯', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^birthPlace','Ù…Ø­Ù„ ØªÙˆÙ„Ø¯', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^instanceOf','Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø²', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^deathPlace','Ù…Ø­Ù„ Ù…Ø±Ú¯', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^death place','Ù…Ø­Ù„ Ù…Ø±Ú¯', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^field','Ù…ÙˆØ¶ÙˆØ¹', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^genre','Ú˜Ø§Ù†Ø±', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^nationality','Ù…Ù„ÛŒØª', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^occupation','Ø´ØºÙ„', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^picture','ØªØµÙˆÛŒØ±', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^ActiveYears','Ø³Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ÛŒØª', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^activeYears','Ø³Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ÛŒØª', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^timezone1 dst','Ù†Ø§Ø­ÛŒÙ‡ Ø²Ù…Ø§Ù†ÛŒ Û±', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^confed_cup','Ø¬Ø§Ù… Ú©Ù†ÙØ¯Ø±Ø§Ø³ÛŒÙˆÙ†', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^distance to London (Î¼)','ÙØ§ØµÙ„Ù‡ ØªØ§ Ù„Ù†Ø¯Ù† (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†)', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^fs_date','ØªØ§Ø±ÛŒØ® Ø³ÛŒØ³ØªÙ… ÙØ§ÛŒÙ„', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^paÅ„stwo','Ú©Ø´ÙˆØ±', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^paÅ„stwo','Ú©Ø´ÙˆØ±', regex=True)\n",
        "df['predicateLabel'] = df['predicateLabel'].str.replace(r'^sp_date','ØªØ§Ø±ÛŒØ® Ø·Ø±Ø­', regex=True)\n",
        "\n",
        "df = df.drop(df[df['predicateLabel'] == '22-rdf-syntax-ns#instanceOf'].index)\n",
        "df = df[~df['objectLabel'].str.contains('relation', case=False, na=False)]\n",
        "df = df[~df['objectLabel'].str.endswith('.JPG')] # Delete Row with .JPG Value\n",
        "df = df[~df['objectLabel'].str.endswith('.jpg')]\n",
        "df = df[~df['objectLabel'].str.endswith('.png')]\n",
        "df = df[~df['objectLabel'].str.endswith('.svg')]\n",
        "df = df[~df['objectLabel'].str.endswith('Pages_using_infobox3cols_with_multidatastyle')]\n",
        "df = df[~df['objectLabel'].str.endswith(':hy:ÕÕµÕ¸Ö‚Õ¦Õ¡Õ¶_Ô³Õ¡Ö€Õ¡Õ£Õ¡Õ·')]\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^Actor','Ø¨Ø§Ø²ÛŒÚ¯Ø±', regex=True)\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^Ali_Daei','Ø¹Ù„ÛŒ Ø¯Ø§ÛŒÛŒ', regex=True)\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^Person','Ø´Ø®Øµ', regex=True)\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^SoccerPlayer','Ø¨Ø§Ø²ÛŒÚ©Ù† Ø³ÙˆÚ©Ø±', regex=True)\n",
        "df['objectLabel'] = df['objectLabel'].str.replace(r'^Writer','Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡', regex=True)\n",
        "\n",
        "# Remove duplicate row\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.to_csv(\"/content/FarsiBase/complete_triples.csv\", index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "QTl059UlE-Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Shuffling And Aggregation(FarsiBase + Deepseek)**"
      ],
      "metadata": {
        "id": "6V8X0yhUvSiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Aggregate FarsiBase Data And DeepSeek Data\n",
        "DeepSeek_df = pd.read_excel('/content/DeepSeek_Triple.xlsx')\n",
        "input_file = '/content/FarsiBase/complete_triples.csv'\n",
        "FarsiBase_df = pd.read_csv(input_file)\n",
        "df = pd.concat([DeepSeek_df, FarsiBase_df], axis=0)\n",
        "\n",
        "# Shuffled Data\n",
        "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "output_file = '/content/FarsiBase/shuffled_triple.csv'\n",
        "shuffled_df.to_csv(output_file ,index=False , encoding='utf-8-sig')\n",
        "print(f\"ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ù‡ ØµÙˆØ±Øª ØªØµØ§Ø¯ÙÛŒ Ø¨Ù‡ Ù‡Ù… Ø±ÛŒØ®ØªÙ‡ Ùˆ Ø¯Ø± '{output_file}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")"
      ],
      "metadata": {
        "id": "PFoAdlUVOuVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PersianILP Normalizing**"
      ],
      "metadata": {
        "id": "maF_LYoZZNdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# Translate Google\n",
        "def translate_relation(relation, target_lang=\"fa\"):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source='auto', target=target_lang).translate(relation)\n",
        "        return translated\n",
        "    except Exception as e:\n",
        "        print(f\"Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡ '{relation}': {e}\")\n",
        "        return relation\n",
        "\n",
        "# Translate Data\n",
        "def normalize_excel(input_path, output_path, use_translation=False):\n",
        "\n",
        "    df = pd.read_csv(input_path)\n",
        "    normalized_relations = []\n",
        "    for relation in df['predicateLabel']:\n",
        "        if pd.isna(relation):\n",
        "            normalized = relation\n",
        "        else:\n",
        "            relation = str(relation)\n",
        "            if use_translation and relation.isascii():\n",
        "              normalized = translate_relation(relation)\n",
        "            else:\n",
        "              normalized = relation\n",
        "        normalized_relations.append(normalized)\n",
        "    df['predicateLabel'] = normalized_relations\n",
        "\n",
        "    # Delete Duplicate Row And Shuffling Data\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¯Ø± '{output_path}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
        "\n",
        "input_excel = \"/content/FarsiBase/shuffled_triple.csv\"\n",
        "output_excel = \"/content/FarsiBase/triple.csv\"\n",
        "normalize_excel(input_path=input_excel,\n",
        "                output_path=output_excel,\n",
        "                use_translation=True)"
      ],
      "metadata": {
        "id": "FX9LuNEXPUsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from collections import Counter\n",
        "\n",
        "def analyze_dataset_for_link_prediction(file_path):\n",
        "\n",
        "    # 1. Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, names=['subject', 'predicate', 'object'])\n",
        "        print(f\"âœ… Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ø³Ù‡â€ŒØªØ§ÛŒÛŒâ€ŒÙ‡Ø§: {len(df):,}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}\")\n",
        "        return\n",
        "\n",
        "    # 2. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡\n",
        "    num_entities = len(set(df['subject']).union(set(df['object'])))\n",
        "    num_relations = len(set(df['predicate']))\n",
        "    print(f\"\\nğŸ“Š Ø¢Ù…Ø§Ø±Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡:\")\n",
        "    print(f\"ØªØ¹Ø¯Ø§Ø¯ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯: {num_entities:,}\")\n",
        "    print(f\"ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ§Ø¨Ø· Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯: {num_relations:,}\")\n",
        "\n",
        "    # 3. Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø±Ø§Ù\n",
        "    G = nx.MultiDiGraph()  # Ú¯Ø±Ø§Ù Ø¬Ù‡Øªâ€ŒØ¯Ø§Ø± Ø¨Ø§ Ø§Ù…Ú©Ø§Ù† Ú†Ù†Ø¯ÛŒÙ† ÛŒØ§Ù„ Ø¨ÛŒÙ† Ú¯Ø±Ù‡â€ŒÙ‡Ø§\n",
        "    for _, row in df.iterrows():\n",
        "        G.add_edge(row['subject'], row['object'], key=row['predicate'])\n",
        "\n",
        "    # 4. ØªØ­Ù„ÛŒÙ„ Ø¯Ø±Ø¬Ù‡ Ú¯Ø±Ù‡â€ŒÙ‡Ø§\n",
        "    degrees = dict(G.degree())\n",
        "    degree_counts = Counter(degrees.values())\n",
        "\n",
        "    print(\"\\nğŸ“ˆ ØªÙˆØ²ÛŒØ¹ Ø¯Ø±Ø¬Ù‡ Ú¯Ø±Ù‡â€ŒÙ‡Ø§:\")\n",
        "    print(f\"â€¢ Ú¯Ø±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø¯Ø±Ø¬Ù‡ Û±: {degree_counts.get(1, 0):,} ({degree_counts.get(1, 0)/G.number_of_nodes():.1%})\")\n",
        "    print(f\"â€¢ Ú¯Ø±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø¯Ø±Ø¬Ù‡ Û²: {degree_counts.get(2, 0):,} ({degree_counts.get(2, 0)/G.number_of_nodes():.1%})\")\n",
        "    print(f\"â€¢ Ú¯Ø±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø¯Ø±Ø¬Ù‡ Û³: {degree_counts.get(3, 0):,} ({degree_counts.get(3, 0)/G.number_of_nodes():.1%})\")\n",
        "\n",
        "    # 5. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ù\n",
        "    density = nx.density(G)\n",
        "    sparsity = 1 - density\n",
        "    avg_degree = sum(degrees.values()) / G.number_of_nodes()\n",
        "    print(\"\\nğŸ” Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ú¯Ø±Ø§Ù:\")\n",
        "    print(f\"ØªØ¹Ø¯Ø§Ø¯ Ú¯Ø±Ù‡â€ŒÙ‡Ø§: {G.number_of_nodes():,}\")\n",
        "    print(f\"ØªØ¹Ø¯Ø§Ø¯ ÛŒØ§Ù„â€ŒÙ‡Ø§: {G.number_of_edges():,}\")\n",
        "    print(f\"Ú†Ú¯Ø§Ù„ÛŒ Ú¯Ø±Ø§Ù: {density:.6f}\")\n",
        "    print(f\"Ø§Ø³Ù¾Ø§Ø±Ø³ Ø¨ÙˆØ¯Ù†: {sparsity:.4f}\")\n",
        "    print(f\"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¯Ø±Ø¬Ù‡ Ú¯Ø±Ù‡â€ŒÙ‡Ø§: {avg_degree:.2f}\")\n",
        "\n",
        "    # 6. Ø¨Ø±Ø±Ø³ÛŒ Ø§ØªØµØ§Ù„Ø§Øª\n",
        "    if nx.is_weakly_connected(G):\n",
        "        print(\"\\nğŸ”„ Ú¯Ø±Ø§Ù Ø¨Ù‡ ØµÙˆØ±Øª Ø¶Ø¹ÛŒÙ Ù…ØªØµÙ„ Ø§Ø³Øª\")\n",
        "    else:\n",
        "        components = nx.number_weakly_connected_components(G)\n",
        "        print(f\"\\nğŸ”— Ú¯Ø±Ø§Ù Ø¯Ø§Ø±Ø§ÛŒ {components} Ø¬Ø²Ø¡ Ù†Ø§Ù‡Ù…Ø¨Ù†Ø¯ Ø§Ø³Øª\")\n",
        "\n",
        "    # 7. ØªØ­Ù„ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù¾ÛŒÙˆÙ†Ø¯\n",
        "    print(\"\\nğŸ§ª Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨ÙˆØ¯Ù† Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù¾ÛŒÙˆÙ†Ø¯:\")\n",
        "\n",
        "    suitability_score = 0\n",
        "\n",
        "    # Ù…Ø¹ÛŒØ§Ø± 1: ØªÙ†ÙˆØ¹ Ø±ÙˆØ§Ø¨Ø·\n",
        "    if num_relations > 50:\n",
        "        print(f\"âœ“ ØªÙ†ÙˆØ¹ Ø±ÙˆØ§Ø¨Ø· Ø¹Ø§Ù„ÛŒ ({num_relations} Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø·Ù‡)\")\n",
        "        suitability_score += 2\n",
        "    elif num_relations > 10:\n",
        "        print(f\"âœ“ ØªÙ†ÙˆØ¹ Ø±ÙˆØ§Ø¨Ø· Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ ({num_relations} Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø·Ù‡)\")\n",
        "        suitability_score += 1\n",
        "    else:\n",
        "        print(f\"âœ— ØªÙ†ÙˆØ¹ Ø±ÙˆØ§Ø¨Ø· Ù†Ø§Ú©Ø§ÙÛŒ ({num_relations} Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø·Ù‡)\")\n",
        "\n",
        "    # Ù…Ø¹ÛŒØ§Ø± 2: Ø§Ø³Ù¾Ø§Ø±Ø³ Ø¨ÙˆØ¯Ù†\n",
        "    if sparsity > 0.99:\n",
        "        print(\"âœ“ Ø§Ø³Ù¾Ø§Ø±Ø³ Ø¨ÙˆØ¯Ù† Ø§ÛŒØ¯Ù‡â€ŒØ¢Ù„ (Ø¨Ø³ÛŒØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù¾ÛŒÙˆÙ†Ø¯)\")\n",
        "        suitability_score += 2\n",
        "    elif sparsity > 0.95:\n",
        "        print(\"âœ“ Ø§Ø³Ù¾Ø§Ø±Ø³ Ø¨ÙˆØ¯Ù† Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„\")\n",
        "        suitability_score += 1\n",
        "    else:\n",
        "        print(\"âœ— Ø§Ø³Ù¾Ø§Ø±Ø³ Ø¨ÙˆØ¯Ù† Ù†Ø§Ú©Ø§ÙÛŒ\")\n",
        "\n",
        "    # Ù…Ø¹ÛŒØ§Ø± 3: ØªÙˆØ²ÛŒØ¹ Ø¯Ø±Ø¬Ù‡\n",
        "    if degree_counts.get(1, 0) < G.number_of_nodes() * 0.4:\n",
        "        print(\"âœ“ ØªÙˆØ²ÛŒØ¹ Ø¯Ø±Ø¬Ù‡ Ù…ØªØ¹Ø§Ø¯Ù„\")\n",
        "        suitability_score += 1\n",
        "    else:\n",
        "        print(f\"âœ— ØªÙˆØ²ÛŒØ¹ Ø¯Ø±Ø¬Ù‡ Ù†Ø§Ù…ØªØ¹Ø§Ø¯Ù„ ({degree_counts.get(1, 0)/G.number_of_nodes():.1%} Ú¯Ø±Ù‡â€ŒÙ‡Ø§ Ø¯Ø±Ø¬Ù‡ Û± Ø¯Ø§Ø±Ù†Ø¯)\")\n",
        "\n",
        "    # Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "    print(\"\\nğŸ¯ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ:\")\n",
        "    if suitability_score >= 4:\n",
        "        print(\"âœ… Ø§ÛŒÙ† Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù¾ÛŒÙˆÙ†Ø¯ Ø¨Ø³ÛŒØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª\")\n",
        "    elif suitability_score >= 2:\n",
        "        print(\"âš ï¸ Ø§ÛŒÙ† Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù¾ÛŒÙˆÙ†Ø¯ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒÛŒ Ø¯Ø§Ø±Ø¯\")\n",
        "    else:\n",
        "        print(\"âŒ Ø§ÛŒÙ† Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù¾ÛŒÙˆÙ†Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª\")\n",
        "\n",
        "# Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡\n",
        "analyze_dataset_for_link_prediction('/content/FarsiBase/triple.csv')"
      ],
      "metadata": {
        "id": "8oanAMglgtPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting three variants of the main dataset**"
      ],
      "metadata": {
        "id": "Tv2JpTGELWsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.makedirs('/content/PersianILP', exist_ok=True)\n",
        "df = pd.read_csv('/content/FarsiBase/triple.csv')\n",
        "n = len(df)\n",
        "idx1 = int(0.25 * n)\n",
        "idx2 = int(0.60 * n)\n",
        "\n",
        "part1 = df.iloc[:idx1].to_csv('/content/PersianILP/PersianILP_V1.csv', index=False, encoding='utf-8-sig')\n",
        "part2 = df.iloc[idx1:idx2].to_csv('/content/PersianILP/PersianILP_V2.csv', index=False, encoding='utf-8-sig')\n",
        "part3 = df.iloc[idx2:].to_csv('/content/PersianILP/PersianILP_V3.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "0Jhms9RWzrC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ØªÙÚ©ÛŒÚ© Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÛŒ Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª\n",
        "def split_train_test_for_file(file_path, test_size=0.2):\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    subjects = set(df.iloc[:, 0].dropna().unique())\n",
        "    objects = set(df.iloc[:, 2].dropna().unique())\n",
        "    all_entities = subjects.union(objects)\n",
        "\n",
        "    train_entities, test_entities = train_test_split(\n",
        "        list(all_entities),\n",
        "        test_size=test_size,\n",
        "        random_state=42)\n",
        "\n",
        "    train_entities = set(train_entities)\n",
        "    test_entities = set(test_entities)\n",
        "\n",
        "    train_mask = df.iloc[:, 0].isin(train_entities) & df.iloc[:, 2].isin(train_entities)\n",
        "    test_mask = df.iloc[:, 0].isin(test_entities) & df.iloc[:, 2].isin(test_entities)\n",
        "    train_df = df[train_mask]\n",
        "    test_df = df[test_mask]\n",
        "    return train_df, test_df\n",
        "\n",
        "# Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§ÛŒÛŒ\n",
        "file_paths = ['/content/PersianILP/PersianILP_V1.csv',\n",
        "              '/content/PersianILP/PersianILP_V2.csv',\n",
        "              '/content/PersianILP/PersianILP_V3.csv']\n",
        "\n",
        "output_dir = '/content/PersianILP-trainTest'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for file_path in file_paths:\n",
        "    base_name = os.path.basename(file_path)\n",
        "    file_name = os.path.splitext(base_name)[0]\n",
        "\n",
        "    version_dir = os.path.join(output_dir, file_name)\n",
        "    os.makedirs(version_dir, exist_ok=True)\n",
        "    train_data, test_data = split_train_test_for_file(file_path, test_size=0.3)\n",
        "\n",
        "    train_output = os.path.join(version_dir, f'train.csv')\n",
        "    test_output = os.path.join(version_dir, f'test.csv')\n",
        "\n",
        "    train_data.to_csv(train_output, index=False, encoding='utf-8-sig')\n",
        "    test_data.to_csv(test_output, index=False, encoding='utf-8-sig')\n",
        "\n",
        "# Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø²ÛŒÙ¾\n",
        "output_dir = '/content/PersianILP-trainTest'\n",
        "zip_path = os.path.join(output_dir, 'PersianILP-data.zip')\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            if not file.endswith('.zip'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, output_dir)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "print(f\"ÙØ§ÛŒÙ„ zip Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ± Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {zip_path}\")"
      ],
      "metadata": {
        "id": "QPzoXZ1uhcr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ù‹Import Dataset**"
      ],
      "metadata": {
        "id": "gdmJ5DBNUlK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ILP_Date_Zip_File = '/content/drive/MyDrive/DataSet/Data_InductiveLinkPrediction.zip'\n",
        "TLP_Data_Zip_File = '/content/drive/MyDrive/DataSet/Data_TransductiveLinkPrediciton.zip'\n",
        "\n",
        "!unzip -q {ILP_Date_Zip_File} -d {'/content'}\n",
        "!unzip -q {TLP_Data_Zip_File} -d {'/content'}\n",
        "\n",
        "datasets = sorted([folder for folder in os.listdir('/content') if os.path.isdir(os.path.join('/content', folder))])\n",
        "def create_dataset_dict(base_dir:str='/content'):\n",
        "    datasets = {}\n",
        "    for dataset_name in os.listdir(base_dir):\n",
        "        dataset_path = os.path.join(base_dir, dataset_name)\n",
        "        if os.path.isdir(dataset_path):\n",
        "            datasets[dataset_name] = {\n",
        "                \"train\": os.path.join(dataset_path, \"train.txt\"),\n",
        "                \"valid\": os.path.join(dataset_path, \"valid.txt\"),\n",
        "                \"test\":  os.path.join(dataset_path, \"test.txt\")}\n",
        "    return datasets\n",
        "\n",
        "# Save Path Dictionay\n",
        "ILP_dataset_paths = create_dataset_dict('/content/Data_InductiveLinkPrediction')\n",
        "ILP_dataset_paths = dict(sorted(ILP_dataset_paths.items()))"
      ],
      "metadata": {
        "id": "dP843TcnUuNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis PersianILP With English BencmarkDataset**"
      ],
      "metadata": {
        "id": "sroJUIhpvhWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from collections import Counter\n",
        "from tabulate import tabulate\n",
        "\n",
        "def load_data(file_path):\n",
        "    sep = \",\" if file_path.endswith('.csv') else \"\\t\"\n",
        "    return pd.read_csv(file_path, sep=sep, header=None, names=[\"head\", \"relation\", \"tail\"])\n",
        "\n",
        "def analyze_graph_metrics(file_path):\n",
        "        df = load_data(file_path)\n",
        "        G = nx.MultiDiGraph()\n",
        "        G.add_edges_from(zip(df[\"head\"], df[\"tail\"], df[\"relation\"]))\n",
        "\n",
        "        degrees = dict(G.degree())\n",
        "        counter = Counter(degrees.values())\n",
        "        avg_deg = sum(degrees.values()) / G.number_of_nodes() if G.number_of_nodes() else 0\n",
        "\n",
        "        return {\n",
        "            \"Deg_1\": counter.get(1, 0),\n",
        "            \"Deg_2\": counter.get(2, 0),\n",
        "            \"Deg_3\": counter.get(3, 0),\n",
        "            \"Avg_Degree\": round(avg_deg, 2),\n",
        "            \"Density\": round(nx.density(G), 6),\n",
        "            \"Sparsity\": round(1 - nx.density(G), 6)\n",
        "        }\n",
        "\n",
        "def process_file(file_path, label):\n",
        "    if os.path.isfile(file_path) and file_path.endswith(('.csv', '.txt')):\n",
        "        metrics = analyze_graph_metrics(file_path)\n",
        "        if metrics:\n",
        "            metrics['Dataset'] = label\n",
        "            return metrics\n",
        "    return None\n",
        "\n",
        "def analyze_all_datasets(all_dirs):\n",
        "    results = []\n",
        "    for base_dir in all_dirs:\n",
        "\n",
        "        for root, _, files in os.walk(base_dir):\n",
        "            dataset_name = os.path.basename(root)\n",
        "            for file in files:\n",
        "                path = os.path.join(root, file)\n",
        "                ext = os.path.splitext(file)[1].lower()\n",
        "                label_type = \"CSV\" if ext == '.csv' else \"TXT\"\n",
        "                label = f\"{dataset_name}_{os.path.splitext(file)[0]}\"\n",
        "                result = process_file(path, label)\n",
        "                if result:\n",
        "                    results.append(result)\n",
        "\n",
        "    return pd.DataFrame(results)[[\"Dataset\", \"Deg_1\", \"Deg_2\", \"Deg_3\", \"Avg_Degree\", \"Density\", \"Sparsity\"]]\n",
        "\n",
        "# Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒÛŒ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ\n",
        "all_dirs = [\n",
        "    \"/content/Data_InductiveLinkPrediction\",\n",
        "    \"/content/PersianILP-trainTest\"]\n",
        "df_result = analyze_all_datasets(all_dirs).sort_values(\"Dataset\")\n",
        "print(tabulate(df_result, headers=\"keys\", tablefmt=\"grid\", showindex=False))"
      ],
      "metadata": {
        "id": "91_AbZb-snS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2- Inductive Link Prediction(CoraGraphDataset)"
      ],
      "metadata": {
        "id": "6PysJRsRIEZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "\n",
        "import dgl\n",
        "import dgl.data\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "0-dmoz4Vfnbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]"
      ],
      "metadata": {
        "id": "MuIZg_9Vgq0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.num_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.num_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.num_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.num_edges())\n",
        "test_neg_u, test_neg_v = (\n",
        "    neg_u[neg_eids[:test_size]],\n",
        "    neg_v[neg_eids[:test_size]],)\n",
        "\n",
        "train_neg_u, train_neg_v = (\n",
        "    neg_u[neg_eids[test_size:]],\n",
        "    neg_v[neg_eids[test_size:]],)"
      ],
      "metadata": {
        "id": "1CgM9xxSg727"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ],
      "metadata": {
        "id": "DdxmZFIcgSRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, \"mean\")\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "Ch-KoseJpPAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())"
      ],
      "metadata": {
        "id": "An9qkhsGpUPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata[\"score\"][:, 0]"
      ],
      "metadata": {
        "id": "cKabS4FmpWoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src[\"h\"], edges.dst[\"h\"]], 1)\n",
        "        return {\"score\": self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata[\"score\"]"
      ],
      "metadata": {
        "id": "JqhsI2qIpdoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(train_g.ndata[\"feat\"].shape[1], 16)\n",
        "pred = DotPredictor()\n",
        "\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    )\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return roc_auc_score(labels, scores)\n",
        "\n",
        "def compute_auc_pr(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return average_precision_score(labels, scores)"
      ],
      "metadata": {
        "id": "M_GYqGBspjVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# in this case, loss will in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata[\"feat\"])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "\n",
        "clear_output()\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "\n",
        "    print(\"AUC\", compute_auc(pos_score, neg_score))\n",
        "    print(\"AUC_PR\", compute_auc_pr(pos_score, neg_score))\n",
        "\n",
        "    # set pos_scores and neg_scores\n",
        "    pos_scores = pos_score.squeeze().detach().cpu().tolist()\n",
        "    neg_scores = neg_score.squeeze().detach().cpu().tolist()\n",
        "\n",
        "    # set Labels\n",
        "    targets_pos = torch.ones(len(pos_scores))\n",
        "    targets_neg = torch.zeros(len(neg_scores))\n",
        "    pos_labels = targets_pos.detach().cpu().tolist()\n",
        "    neg_labels = targets_neg.detach().cpu().tolist()\n",
        "\n",
        "    # convert to tensors for further processing\n",
        "    pos_tensor = torch.tensor(pos_scores, dtype=torch.float32).view(-1, 1)\n",
        "    neg_tensor = torch.tensor(neg_scores, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    scores = torch.cat([pos_tensor, neg_tensor], dim=1)  # shape: [batch_size, 2]\n",
        "    scores = torch.softmax(scores, dim=1)\n",
        "    scores = scores.detach().cpu().numpy()\n",
        "\n",
        "    rank = np.argwhere(np.argsort(scores, axis=1)[:, ::-1] == 0)[:, 1] + 1\n",
        "    ranks += rank.tolist()\n",
        "\n",
        "    hit1 = [1 if item <= 1 else 0 for item in rank]\n",
        "    hit3 = [1 if item <= 3 else 0 for item in rank]\n",
        "    hit10 = [1 if item <= 10 else 0 for item in rank]\n",
        "\n",
        "    mrr = np.mean(1.0 / np.array(ranks)).item()\n",
        "    hit1 = np.mean(hit1)\n",
        "    hit3 = np.mean(hit3)\n",
        "    hit10 = np.mean(hit10)\n",
        "    print(f'mrr: {mrr}')\n",
        "    print(f'hit1: {hit1}')\n",
        "    print(f'hit3:{hit3}')\n",
        "    print(f'hit10:{hit10}')"
      ],
      "metadata": {
        "id": "tZMGBguMpkcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3- Inductive Link Prediction(PersianILP)"
      ],
      "metadata": {
        "id": "nPOCJCXwfotg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ILP_Date_Zip_File = '/content/drive/MyDrive/DataSet/ILPDataSet.zip'\n",
        "!unzip -q {ILP_Date_Zip_File} -d {'/content'}\n",
        "\n",
        "datasets = sorted([folder for folder in os.listdir('/content') if os.path.isdir(os.path.join('/content', folder))])\n",
        "def create_dataset_dict(base_dir: str = '/content'):\n",
        "    datasets = {}\n",
        "    for dataset_name in os.listdir(base_dir):\n",
        "        dataset_path = os.path.join(base_dir, dataset_name)\n",
        "        if os.path.isdir(dataset_path):\n",
        "            dataset_files = {\n",
        "                \"train\": None,\n",
        "                \"valid\": None,\n",
        "                \"test\": None}\n",
        "\n",
        "            # Check for both .txt and .csv files\n",
        "            for split in dataset_files.keys():\n",
        "                txt_path = os.path.join(dataset_path, f\"{split}.txt\")\n",
        "                csv_path = os.path.join(dataset_path, f\"{split}.csv\")\n",
        "\n",
        "                if os.path.exists(txt_path):\n",
        "                    dataset_files[split] = txt_path\n",
        "                elif os.path.exists(csv_path):\n",
        "                    dataset_files[split] = csv_path\n",
        "\n",
        "            datasets[dataset_name] = dataset_files\n",
        "\n",
        "    return datasets\n",
        "\n",
        "\n",
        "# Save Path Dictionay\n",
        "ILP_dataset_paths = create_dataset_dict('/content/ILPDataSet')\n",
        "ILP_dataset_paths = dict(sorted(ILP_dataset_paths.items()))"
      ],
      "metadata": {
        "id": "BQ6SLucSJmV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link Prediction By DGL**"
      ],
      "metadata": {
        "id": "NyHsMieP32dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "import pandas as pd\n",
        "from dgl.data import DGLDataset\n",
        "\n",
        "class PersianDGLDataset(DGLDataset):\n",
        "    def __init__(self, train_file, test_file, seed=42):\n",
        "        self.train_file = train_file\n",
        "        self.test_file = test_file\n",
        "        self.seed = seed\n",
        "        self.process()\n",
        "        super().__init__(name=\"PersianLinkPrediction\")\n",
        "\n",
        "    def process(self):\n",
        "        # Initialize mappings\n",
        "        self.entity2id = {}\n",
        "        self.relation2id = {}\n",
        "        ent_id, rel_id = 0, 0\n",
        "\n",
        "        # Process training data\n",
        "        train_triples = self._load_and_process_file(self.train_file, ent_id, rel_id)\n",
        "        ent_id, rel_id = len(self.entity2id), len(self.relation2id)\n",
        "\n",
        "        # Process test data (using same mappings)\n",
        "        test_triples = self._load_and_process_file(self.test_file, ent_id, rel_id)\n",
        "\n",
        "        # Build graphs\n",
        "        self.graphs = {\n",
        "            \"train\": self._build_graph(train_triples),\n",
        "            \"test\": self._build_graph(test_triples)\n",
        "        }\n",
        "\n",
        "    def _load_file(self, file_path):\n",
        "        \"\"\"Load file based on its extension\"\"\"\n",
        "        if file_path.endswith('.csv'):\n",
        "            return pd.read_csv(file_path)\n",
        "        elif file_path.endswith('.txt'):\n",
        "            return pd.read_csv(file_path, sep='\\t', header=None,\n",
        "                             names=['subjectLabel', 'predicateLabel', 'objectLabel'])\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file format. Only .csv and .txt files are supported.\")\n",
        "\n",
        "    def _load_and_process_file(self, file_path, ent_id_start, rel_id_start):\n",
        "        \"\"\"Load and process a single file, updating mappings\"\"\"\n",
        "        triples = []\n",
        "        df = self._load_file(file_path)\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            h, r, t = row['subjectLabel'], row['predicateLabel'], row['objectLabel']\n",
        "\n",
        "            # Update entity mappings\n",
        "            for ent in [h, t]:\n",
        "                if ent not in self.entity2id:\n",
        "                    self.entity2id[ent] = ent_id_start\n",
        "                    ent_id_start += 1\n",
        "\n",
        "            # Update relation mappings\n",
        "            if r not in self.relation2id:\n",
        "                self.relation2id[r] = rel_id_start\n",
        "                rel_id_start += 1\n",
        "\n",
        "            triples.append((\n",
        "                self.entity2id[h],\n",
        "                self.relation2id[r],\n",
        "                self.entity2id[t]))\n",
        "\n",
        "        return triples\n",
        "\n",
        "    def _build_graph(self, triples):\n",
        "        \"\"\"Build DGL graph from triples\"\"\"\n",
        "        src, rel, dst = zip(*triples)\n",
        "        src = torch.tensor(src)\n",
        "        dst = torch.tensor(dst)\n",
        "        rel = torch.tensor(rel)\n",
        "\n",
        "        g = dgl.graph((src, dst), num_nodes=len(self.entity2id))\n",
        "        g.edata[\"e_type\"] = rel\n",
        "        g.edata[\"edge_mask\"] = torch.ones(g.num_edges(), dtype=torch.bool)\n",
        "        g.ndata[\"ntype\"] = torch.zeros(g.num_nodes(), dtype=torch.int)\n",
        "        g.ndata[\"feat\"] = torch.randn(g.num_nodes(), 64)\n",
        "        return g\n",
        "\n",
        "    def __getitem__(self, split):\n",
        "        return self.graphs[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "class GraphBatchDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, graphs, pos_graphs, neg_graphs):\n",
        "        self.graphs = graphs\n",
        "        self.pos_graphs = pos_graphs\n",
        "        self.neg_graphs = neg_graphs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"graph\": self.graphs[idx],\n",
        "            \"pos_graph\": self.pos_graphs[idx],\n",
        "            \"neg_graph\": self.neg_graphs[idx]}\n",
        "\n",
        "\n",
        "dataset = PersianDGLDataset(train_file = ILP_dataset_paths['PersianILP_V1']['train'],\n",
        "                            test_file = ILP_dataset_paths['PersianILP_V1']['test'])\n",
        "train_g = dataset[\"train\"]\n",
        "test_g = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "PUYSCAkJU_26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Positive Graph And Negative Graph**"
      ],
      "metadata": {
        "id": "lg6BZ_u1TYFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import dgl\n",
        "import scipy.sparse as sp\n",
        "from tabulate import tabulate\n",
        "import torch\n",
        "\n",
        "class GraphNegativeSampler:\n",
        "    def __init__(self, train_graph, test_graph, train_neg_ratio=1.0, test_neg_ratio=1.0):\n",
        "        self.train_graph = train_graph\n",
        "        self.test_graph = test_graph\n",
        "        self.train_neg_ratio = train_neg_ratio\n",
        "        self.test_neg_ratio = test_neg_ratio\n",
        "        self.train_pos_g, self.train_neg_g = self._prepare_graphs(train_graph, train_neg_ratio)\n",
        "        self.test_pos_g, self.test_neg_g = self._prepare_graphs(test_graph, test_neg_ratio)\n",
        "\n",
        "    def _generate_negative_samples(self, graph):\n",
        "        u, v = graph.edges()\n",
        "        adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())),\n",
        "                          shape=(graph.num_nodes(), graph.num_nodes()))\n",
        "        return np.where(1 - adj.todense() - np.eye(graph.num_nodes()) != 0)\n",
        "\n",
        "    def _prepare_graphs(self, graph, ratio):\n",
        "        return ( self._create_positive_graph(graph),\n",
        "                 self._create_negative_graph(graph, ratio))\n",
        "\n",
        "    def _create_positive_graph(self, graph):\n",
        "        g = dgl.graph(graph.edges(), num_nodes=graph.num_nodes())\n",
        "        g.edata[\"e_type\"] = graph.edata[\"e_type\"]\n",
        "        g.ndata.update({k: graph.ndata[k] for k in [\"feat\", \"ntype\"]})\n",
        "        return g\n",
        "\n",
        "    def _create_negative_graph(self, graph, ratio):\n",
        "        neg_u, neg_v = self._generate_negative_samples(graph)\n",
        "        num_samples = int(graph.num_edges() * ratio)\n",
        "        replace = len(neg_u) < num_samples\n",
        "        sample_ids = np.random.choice(len(neg_u), num_samples, replace=replace)\n",
        "\n",
        "        g = dgl.graph((neg_u[sample_ids], neg_v[sample_ids]), num_nodes=graph.num_nodes())\n",
        "        g.edata[\"e_type\"] = torch.randint(0, graph.edata[\"e_type\"].max().item()+1, (g.num_edges(),))\n",
        "        g.ndata.update({\n",
        "            \"feat\": graph.ndata[\"feat\"],\n",
        "            \"ntype\": torch.ones(graph.num_nodes(), dtype=torch.int)})\n",
        "        return g\n",
        "\n",
        "    @property\n",
        "    def training_graphs(self):\n",
        "        return self.train_pos_g, self.train_neg_g\n",
        "\n",
        "    @property\n",
        "    def test_graphs(self):\n",
        "        return self.test_pos_g, self.test_neg_g\n",
        "\n",
        "# Sampling From Knowladge Graph\n",
        "sampler = GraphNegativeSampler(dataset['train'],\n",
        "                               dataset['test'],\n",
        "                               train_neg_ratio=1,\n",
        "                               test_neg_ratio=1)\n",
        "\n",
        "train_pos, train_neg = sampler.training_graphs\n",
        "test_pos, test_neg = sampler.test_graphs"
      ],
      "metadata": {
        "id": "ib9tMN65QxIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv\n",
        "import torch.nn as nn\n",
        "\n",
        "class ImprovedGraphSAGE(nn.Module):\n",
        "  def __init__(self, in_feats, h_feats, out_feats, dropout=0.5):\n",
        "        super(ImprovedGraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
        "        self.conv2 = SAGEConv(h_feats, out_feats, \"mean\")\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "import dgl.function as fn\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
        "            return g.edata[\"score\"][:, 0]"
      ],
      "metadata": {
        "id": "TzIhEJdJUCK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import dgl\n",
        "\n",
        "def train_model(model,\n",
        "                pred,\n",
        "                dataloader,\n",
        "                epochs,\n",
        "                lr=0.01):\n",
        "\n",
        "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(),\n",
        "                                                 pred.parameters()),\n",
        "                                                 lr=lr)\n",
        "\n",
        "    all_losses = []\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            batch_graph = batch[\"graph\"]    # Ú¯Ø±Ø§Ù Ø§ØµÙ„ÛŒ\n",
        "            pos_graph = batch[\"pos_graph\"]  # Ú¯Ø±Ø§Ù Ù…Ø«Ø¨Øª\n",
        "            neg_graph = batch[\"neg_graph\"]  # Ú¯Ø±Ø§Ù Ù…Ù†ÙÛŒ\n",
        "\n",
        "            # Forward pass\n",
        "            h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "            pos_score = pred(pos_graph, h)\n",
        "            neg_score = pred(neg_graph, h)\n",
        "            loss = compute_loss(pos_score,neg_score)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            e = epoch\n",
        "            loss = epoch_loss\n",
        "\n",
        "        all_losses.append(epoch_loss)\n",
        "\n",
        "    print(f\"\\nEpoch: {e}, Loss: {loss:.4f}\")\n",
        "    return h, all_losses\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)"
      ],
      "metadata": {
        "id": "RG5q7F62ULlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import average_precision_score\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "class GraphEvaluator:\n",
        "    def __init__(self, metrics, pred, test_pos_g, test_neg_g, h, dataset_name, k=10):\n",
        "        self.metrics = metrics\n",
        "        self.dataset_name = dataset_name\n",
        "        self.k = k\n",
        "        self.__evaluate(pred, test_pos_g, test_neg_g, h)\n",
        "\n",
        "    def compute_metrics(self, pos_score, neg_score):\n",
        "        pos_array = pos_score.cpu().detach().numpy()\n",
        "        neg_array = neg_score.cpu().detach().numpy()\n",
        "        labels_pr = np.concatenate([np.ones_like(pos_array), np.zeros_like(neg_array)])\n",
        "        scores_pr = np.concatenate([pos_array, neg_array])\n",
        "        auc_pr = average_precision_score(labels_pr, scores_pr)\n",
        "\n",
        "        ranks = []\n",
        "        hits_at_k = []\n",
        "        for pos, neg in zip(pos_score, neg_score):\n",
        "            neg = neg.view(-1)\n",
        "            pos = pos.view(-1)\n",
        "            all_scores = torch.cat([neg, pos])\n",
        "            sorted_scores, indices = torch.sort(all_scores, descending=True)\n",
        "            rank = (indices == len(neg)).nonzero(as_tuple=True)[0].item() + 1\n",
        "            ranks.append(rank)\n",
        "            hits_at_k.append(1 if rank <= self.k else 0)\n",
        "\n",
        "        mrr = np.mean([1.0 / rank for rank in ranks])\n",
        "        hit_at_k = np.mean(hits_at_k)\n",
        "        loss = F.binary_cross_entropy_with_logits(torch.cat([pos_score, neg_score]),\n",
        "                                                  torch.cat([torch.ones(pos_score.shape[0]),\n",
        "                                                             torch.zeros(neg_score.shape[0])]))\n",
        "\n",
        "        return {\"AUC-PR\": auc_pr, \"MRR\": mrr, f\"Hit@{self.k}\": hit_at_k, \"Loss\": loss.item()}\n",
        "\n",
        "    def display_metrics(self):\n",
        "        '''Ù†Ù…Ø§ÛŒØ´ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ metrics Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø¬Ø¯ÙˆÙ„'''\n",
        "        table = PrettyTable()\n",
        "        table.field_names = [\"Dataset\"] + list(next(iter(self.metrics.values())).keys())\n",
        "\n",
        "        for dataset, metrics in self.metrics.items():\n",
        "            row = [dataset] + list(metrics.values())\n",
        "            table.add_row(row)\n",
        "\n",
        "        print(table)\n",
        "\n",
        "    def __evaluate(self, pred, test_pos_g, test_neg_g, h):\n",
        "        '''Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ (ØªØ§Ø¨Ø¹ Ø®ØµÙˆØµÛŒ)'''\n",
        "        with torch.no_grad():\n",
        "            pos_score = pred(test_pos_g, h)\n",
        "            neg_score = pred(test_neg_g, h)\n",
        "            new_metrics = self.compute_metrics(pos_score, neg_score)\n",
        "            self.metrics[self.dataset_name] = new_metrics\n",
        "\n",
        "        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø¬Ø¯ÙˆÙ„\n",
        "        self.display_metrics()"
      ],
      "metadata": {
        "id": "r-MvesGSUT1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link Prediction With GraphSAGE + Dot Predictor**"
      ],
      "metadata": {
        "id": "bq8EHus7HT-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Imports =======\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from tabulate import tabulate\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "from sklearn import metrics\n",
        "\n",
        "# ==== Hyperparameters ====\n",
        "h_feats = 16\n",
        "out_feats = 10\n",
        "dropout = 0.5\n",
        "epochs = 2000\n",
        "lr = 0.01\n",
        "k = 10\n",
        "train_neg_ratio = 2\n",
        "test_neg_ratio = 1\n",
        "result = {'DataSet': 'Persian_LP'}\n",
        "\n",
        "# ==== Step 1: Dataset Preparation ====\n",
        "graphs = PersianDGLDataset(train_file=ILP_dataset_paths['PersianILP_V1']['train'],\n",
        "                           test_file =ILP_dataset_paths['PersianILP_V1']['test'])\n",
        "\n",
        "sampler = GraphNegativeSampler(\n",
        "    graphs['train'], graphs['test'],\n",
        "    train_neg_ratio=train_neg_ratio,\n",
        "    test_neg_ratio=test_neg_ratio\n",
        ")\n",
        "train_pos_g, train_neg_g = sampler.training_graphs\n",
        "test_pos_g,  test_neg_g  = sampler.test_graphs\n",
        "\n",
        "train_dataset = GraphBatchDataset([graphs['train']], [train_pos_g], [train_neg_g])\n",
        "train_loader  = GraphDataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "test_dataset = GraphBatchDataset([graphs['test']], [test_pos_g], [test_neg_g])\n",
        "test_loader  = GraphDataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "# ==== Step 2: Training ====\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([\n",
        "        torch.ones(pos_score.shape[0]),\n",
        "        torch.zeros(neg_score.shape[0])\n",
        "    ])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "feats = graphs[\"train\"].ndata[\"feat\"].shape[1]\n",
        "model = ImprovedGraphSAGE(\n",
        "    in_feats=feats,\n",
        "    h_feats=h_feats,\n",
        "    out_feats=out_feats,\n",
        "    dropout=dropout\n",
        ")\n",
        "pred = DotPredictor()\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()),\n",
        "    lr=lr\n",
        ")\n",
        "\n",
        "all_losses = []\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    epoch_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        batch_graph = batch[\"graph\"]\n",
        "        pos_graph   = batch[\"pos_graph\"]\n",
        "        neg_graph   = batch[\"neg_graph\"]\n",
        "\n",
        "        # Forward\n",
        "        h          = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_score  = pred(pos_graph, h)\n",
        "        neg_score  = pred(neg_graph, h)\n",
        "        loss       = compute_loss(pos_score, neg_score)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    all_losses.append(epoch_loss)\n",
        "\n",
        "# ==== Step3: Testing =====\n",
        "pos_scores = []\n",
        "pos_labels = []\n",
        "neg_scores = []\n",
        "neg_labels = []\n",
        "\n",
        "hit1_list = []\n",
        "hit3_list = []\n",
        "hit10_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    ranks = []\n",
        "    for b_idx, batch in enumerate(test_loader):\n",
        "\n",
        "        batch_graph = batch['graph']\n",
        "        pos_graph   = batch['pos_graph']\n",
        "        neg_graph   = batch['neg_graph']\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ù‡Ø§ÛŒ Ù…Ø«Ø¨Øª Ùˆ Ù…Ù†ÙÛŒ\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        score_pos = pred(pos_graph, h)  # Ø®Ø±ÙˆØ¬ÛŒ shape: (batch_size, 1)\n",
        "        score_neg = pred(neg_graph, h)  # Ø®Ø±ÙˆØ¬ÛŒ shape: (batch_size, 1)\n",
        "\n",
        "        # Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ù‡ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§\n",
        "        pos_scores += score_pos.squeeze().detach().cpu().tolist()\n",
        "        neg_scores += score_neg.squeeze().detach().cpu().tolist()\n",
        "\n",
        "        # Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§\n",
        "        targets_pos = torch.ones(len(score_pos))\n",
        "        targets_neg = torch.zeros(len(score_neg))\n",
        "        pos_labels += targets_pos.detach().cpu().tolist()\n",
        "        neg_labels += targets_neg.detach().cpu().tolist()\n",
        "\n",
        "        # Ø³Ø§Ø®Øª Ù…Ø§ØªØ±ÛŒØ³ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ softmax Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡\n",
        "        score_pos = score_pos.view(-1, 1)\n",
        "        score_neg = score_neg.view(-1, 1)\n",
        "        scores = torch.cat([score_pos, score_neg], dim=1)  # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ†Ú©Ù‡ Ù‡Ø± Ø¯Ùˆ [batch_size, 1] Ø¨Ø§Ø´Ù†Ø¯\n",
        "        scores = torch.softmax(scores, dim=1)\n",
        "        scores = scores.detach().cpu().numpy()\n",
        "\n",
        "        rank = np.argwhere(np.argsort(scores, axis=1)[:, ::-1] == 0)[:, 1] + 1\n",
        "        ranks += rank.tolist()\n",
        "\n",
        "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Hit@K\n",
        "        hit1 = [1 if item <= 1 else 0 for item in rank]\n",
        "        hit3 = [1 if item <= 3 else 0 for item in rank]\n",
        "        hit10 = [1 if item <= 10 else 0 for item in rank]\n",
        "        hit1_list += hit1\n",
        "        hit3_list += hit3\n",
        "        hit10_list += hit10\n",
        "\n",
        "result = {}\n",
        "result[\"Dataset\"] = \"Persian_LP\"\n",
        "result[\"AUC\"] = metrics.roc_auc_score(pos_labels + neg_labels, pos_scores + neg_scores)\n",
        "result[\"AUC_PR\"] = metrics.average_precision_score(pos_labels + neg_labels, pos_scores + neg_scores)\n",
        "result[\"MRR\"] = np.mean(1.0 / np.array(ranks)).item()\n",
        "result[\"Hit1\"] = np.mean(hit1_list)\n",
        "result[\"Hit3\"] = np.mean(hit3_list)\n",
        "result[\"Hit10\"] = np.mean(hit10_list)\n",
        "print(result)\n",
        "\n",
        "headers = ['Dataset', 'AUC' ,'AUC_PR', 'MRR', 'Hit1', 'Hit3', 'Hit10']\n",
        "values  = [[result[key] for key in headers]]\n",
        "print(\"\\n\" + tabulate(\n",
        "    values,\n",
        "    headers=headers,\n",
        "    tablefmt=\"fancy_grid\",\n",
        "    floatfmt=\".4f\",\n",
        "    stralign=\"center\",\n",
        "    numalign=\"left\"))"
      ],
      "metadata": {
        "id": "GeiPLUKEc3RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Imports =======\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from tabulate import tabulate\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "\n",
        "# ======== Hyperparameters =======\n",
        "h_feats = 32\n",
        "out_feats = 16\n",
        "dropout = 0.5\n",
        "epochs = 2000\n",
        "lr = 0.01\n",
        "k = 10\n",
        "train_neg_ratio = 1\n",
        "test_neg_ratio = 1\n",
        "\n",
        "# ======== Dataset Preparation =======\n",
        "graphs = PersianDGLDataset(\n",
        "    train_file=ILP_dataset_paths['WN18RR_v1_ind']['train'],\n",
        "    test_file=ILP_dataset_paths['WN18RR_v1_ind']['test'])\n",
        "\n",
        "sampler = GraphNegativeSampler(\n",
        "    graphs['train'], graphs['test'],\n",
        "    train_neg_ratio=train_neg_ratio,\n",
        "    test_neg_ratio=test_neg_ratio)\n",
        "\n",
        "train_pos_g, train_neg_g = sampler.training_graphs\n",
        "test_pos_g, test_neg_g = sampler.test_graphs\n",
        "\n",
        "\n",
        "train_dataset = GraphBatchDataset([graphs['train']], [train_pos_g], [train_neg_g])\n",
        "train_loader = GraphDataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "test_dataset = GraphBatchDataset([graphs['test']], [test_pos_g], [test_neg_g])\n",
        "test_loader = GraphDataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "# ======== Model Initialization =======\n",
        "feats = graphs[\"train\"].ndata[\"feat\"].shape[1]\n",
        "model = ImprovedGraphSAGE(\n",
        "    in_feats=feats,\n",
        "    h_feats=h_feats,\n",
        "    out_feats=out_feats,\n",
        "    dropout=dropout)\n",
        "\n",
        "pred = DotPredictor()\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()),\n",
        "    lr=lr\n",
        ")\n",
        "\n",
        "# ======== Training Function =======\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([\n",
        "        torch.ones(pos_score.shape[0]),\n",
        "        torch.zeros(neg_score.shape[0])\n",
        "    ])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "# ======== Training Loop =======\n",
        "all_losses = []\n",
        "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch_graph = batch[\"graph\"]\n",
        "        pos_graph = batch[\"pos_graph\"]\n",
        "        neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "        # Forward pass\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_score = pred(pos_graph, h)\n",
        "        neg_score = pred(neg_graph, h)\n",
        "        loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    all_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "# ======== Evaluation =======\n",
        "@torch.no_grad()\n",
        "def prediction_model(model, test_loader):\n",
        "    model.eval()\n",
        "    logits = []\n",
        "    labels = []\n",
        "    indexes = []\n",
        "\n",
        "    query_id = 0\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        batch_graph = batch['graph']\n",
        "        pos_graph = batch['pos_graph']\n",
        "        neg_graph = batch['neg_graph']\n",
        "\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_scores = pred(pos_graph, h)\n",
        "        neg_scores = pred(neg_graph, h)\n",
        "\n",
        "        for pos_score in pos_scores:\n",
        "            # Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡â€ŒÛŒ Ù…Ø«Ø¨Øª ÛŒÚ© query Ø§Ø³Øª\n",
        "            all_scores = torch.cat([pos_score.unsqueeze(0), neg_scores])\n",
        "            all_labels = torch.cat([\n",
        "                torch.ones(1, dtype=torch.bool),\n",
        "                torch.zeros(neg_scores.shape[0], dtype=torch.bool)])\n",
        "            all_indexes = torch.full((all_scores.shape[0],), query_id, dtype=torch.long)\n",
        "\n",
        "            logits.append(all_scores)\n",
        "            labels.append(all_labels)\n",
        "            indexes.append(all_indexes)\n",
        "\n",
        "            query_id += 1\n",
        "\n",
        "    logits = torch.cat(logits, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "    indexes = torch.cat(indexes, dim=0)\n",
        "    return logits, labels, indexes\n",
        "\n",
        "# Get predictions\n",
        "logits, labels, indexes = prediction_model(model, test_loader)\n",
        "\n",
        "# Compute metrics\n",
        "auc = roc_auc_score(labels.numpy(), logits.numpy())\n",
        "auc_pr = average_precision_score(labels.numpy(), logits.numpy())\n",
        "\n",
        "# Initialize metrics\n",
        "mrr_metric = RetrievalMRR()\n",
        "hit_rate_metric = RetrievalHitRate(top_k=10)\n",
        "\n",
        "# Update metrics with all predictions\n",
        "mrr_metric.update(logits, labels, indexes)\n",
        "hit_rate_metric.update(logits, labels, indexes)\n",
        "\n",
        "# Compute final metrics\n",
        "mrr = mrr_metric.compute().item()\n",
        "hit_at_k = hit_rate_metric.compute().item()\n",
        "\n",
        "# Compute loss\n",
        "loss = F.binary_cross_entropy_with_logits(logits, labels.float()).item()\n",
        "\n",
        "# Store results\n",
        "dataset_name = 'WN18RR_v1_ind'\n",
        "result_dict = {\n",
        "    dataset_name: {\n",
        "        \"AUC\": auc,\n",
        "        \"AUC_PR\": auc_pr,\n",
        "        \"MRR\": mrr,\n",
        "        \"HIT_at_K\": hit_at_k,\n",
        "        \"LOSS\": loss\n",
        "    }\n",
        "}\n",
        "\n",
        "# ======== Display Results =======\n",
        "headers = ['DataSet', 'AUC', 'AUC_PR', 'MRR', 'HIT_at_K', 'LOSS']\n",
        "table_data = [[\n",
        "    dataset_name,\n",
        "    result_dict[dataset_name]['AUC'],\n",
        "    result_dict[dataset_name]['AUC_PR'],\n",
        "    result_dict[dataset_name]['MRR'],\n",
        "    result_dict[dataset_name]['HIT_at_K'],\n",
        "    result_dict[dataset_name]['LOSS']\n",
        "]]\n",
        "\n",
        "print(\"\\nÙ†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´:\")\n",
        "print(tabulate(\n",
        "    table_data,\n",
        "    headers=headers,\n",
        "    tablefmt=\"fancy_grid\",\n",
        "    floatfmt=\".4f\",\n",
        "    stralign=\"center\",\n",
        "    numalign=\"left\"))\n",
        "\n",
        "# ======== Save Model =======\n",
        "torch.save(model.state_dict(), f'model_{dataset_name}.pth')"
      ],
      "metadata": {
        "id": "64PrZkgIUWuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Imports =======\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from tabulate import tabulate\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "\n",
        "# ======== Hyperparameters =======\n",
        "h_feats = 64\n",
        "out_feats = 16\n",
        "dropout = 0.5\n",
        "epochs = 2000\n",
        "lr = 0.001\n",
        "k = 10\n",
        "train_neg_ratio = 1\n",
        "test_neg_ratio = 50\n",
        "\n",
        "# ======== Dataset Preparation =======\n",
        "graphs = PersianDGLDataset(\n",
        "    train_file=ILP_dataset_paths['WN18RR_v1_ind']['train'],\n",
        "    test_file=ILP_dataset_paths['WN18RR_v1_ind']['test']\n",
        ")\n",
        "\n",
        "sampler = GraphNegativeSampler(\n",
        "    graphs['train'], graphs['test'],\n",
        "    train_neg_ratio=train_neg_ratio,\n",
        "    test_neg_ratio=test_neg_ratio)\n",
        "\n",
        "train_pos_g, train_neg_g = sampler.training_graphs\n",
        "test_pos_g, test_neg_g = sampler.test_graphs\n",
        "\n",
        "\n",
        "train_dataset = GraphBatchDataset([graphs['train']], [train_pos_g], [train_neg_g])\n",
        "train_loader = GraphDataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "test_dataset = GraphBatchDataset([graphs['test']], [test_pos_g], [test_neg_g])\n",
        "test_loader = GraphDataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "# ======== Model Initialization =======\n",
        "feats = graphs[\"train\"].ndata[\"feat\"].shape[1]\n",
        "model = ImprovedGraphSAGE(\n",
        "    in_feats=feats,\n",
        "    h_feats=h_feats,\n",
        "    out_feats=out_feats,\n",
        "    dropout=dropout\n",
        ")\n",
        "pred = DotPredictor()\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()),\n",
        "    lr=lr\n",
        ")\n",
        "\n",
        "# ======== Training Function =======\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([\n",
        "        torch.ones(pos_score.shape[0]),\n",
        "        torch.zeros(neg_score.shape[0])\n",
        "    ])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "# ======== Training Loop =======\n",
        "all_losses = []\n",
        "for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch_graph = batch[\"graph\"]\n",
        "        pos_graph = batch[\"pos_graph\"]\n",
        "        neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "        # Forward pass\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_score = pred(pos_graph, h)\n",
        "        neg_score = pred(neg_graph, h)\n",
        "        loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    all_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "# ======== Evaluation =======\n",
        "@torch.no_grad()\n",
        "def prediction_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_pos_scores = []\n",
        "    all_neg_scores = []\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        batch_graph = batch['graph']\n",
        "        pos_graph = batch['pos_graph']\n",
        "        neg_graph = batch['neg_graph']\n",
        "\n",
        "        h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_scores = pred(pos_graph, h)\n",
        "        neg_scores = pred(neg_graph, h)\n",
        "\n",
        "        all_pos_scores.append(pos_scores.cpu())\n",
        "        all_neg_scores.append(neg_scores.cpu())\n",
        "\n",
        "    return all_pos_scores, all_neg_scores\n",
        "\n",
        "def calculate_mrr(pos_scores, neg_scores):\n",
        "    reciprocal_ranks = []\n",
        "\n",
        "    for pos_batch, neg_batch in zip(pos_scores, neg_scores):\n",
        "        for pos_score in pos_batch:\n",
        "\n",
        "            combined_scores = torch.cat([neg_batch, pos_score.unsqueeze(0)])\n",
        "            sorted_scores, indices = torch.sort(combined_scores, descending=True)\n",
        "            pos_index = len(combined_scores) - 1  # Ú†ÙˆÙ† Ù†Ù…Ø±Ù‡â€ŒÛŒ Ù…Ø«Ø¨Øª Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
        "            rank = (indices == pos_index).nonzero(as_tuple=True)[0].item() + 1\n",
        "            reciprocal_ranks.append(1.0 / rank)\n",
        "\n",
        "    return np.mean(reciprocal_ranks) if reciprocal_ranks else 0.0\n",
        "\n",
        "def calculate_hit_at_k(pos_scores, neg_scores, k=10):\n",
        "    hits = 0\n",
        "    total = 0\n",
        "\n",
        "    for pos_batch, neg_batch in zip(pos_scores, neg_scores):\n",
        "        for pos_score in pos_batch:\n",
        "            # ØªØ±Ú©ÛŒØ¨ Ù†Ù…Ø±Ù‡â€ŒÛŒ Ù…Ø«Ø¨Øª Ø¨Ø§ Ù†Ù…Ø±Ø§Øª Ù…Ù†ÙÛŒ\n",
        "            combined_scores = torch.cat([neg_batch, pos_score.unsqueeze(0)])\n",
        "\n",
        "            # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ù†Ø²ÙˆÙ„ÛŒ Ù†Ù…Ø±Ø§Øª\n",
        "            sorted_scores, indices = torch.sort(combined_scores, descending=True)\n",
        "\n",
        "            # Ù…ÙˆÙ‚Ø¹ÛŒØª Ù†Ù…Ø±Ù‡â€ŒÛŒ Ù…Ø«Ø¨Øª Ø¯Ø± Ù„ÛŒØ³Øª Ù…Ø±ØªØ¨â€ŒØ´Ø¯Ù‡\n",
        "            pos_index = len(combined_scores) - 1  # Ú†ÙˆÙ† Ù†Ù…Ø±Ù‡â€ŒÛŒ Ù…Ø«Ø¨Øª Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡\n",
        "            rank = (indices == pos_index).nonzero(as_tuple=True)[0].item() + 1\n",
        "\n",
        "            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø±ØªØ¨Ù‡ Ø¯Ø± Ø¨ÛŒÙ† K Ø¨Ø±ØªØ± Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯\n",
        "            if rank <= k:\n",
        "                hits += 1\n",
        "            total += 1\n",
        "\n",
        "    return hits / total if total else 0.0\n",
        "\n",
        "# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§\n",
        "all_pos_scores, all_neg_scores = prediction_model(model, test_loader)\n",
        "mrr = calculate_mrr(all_pos_scores, all_neg_scores)\n",
        "hit_at_k = calculate_hit_at_k(all_pos_scores, all_neg_scores, k=k)\n",
        "\n",
        "# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø§ÛŒØ± Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§\n",
        "all_labels = np.concatenate([\n",
        "    np.ones(sum(len(x) for x in all_pos_scores)),\n",
        "    np.zeros(sum(len(x) for x in all_neg_scores))\n",
        "])\n",
        "all_scores = np.concatenate([\n",
        "    torch.cat(all_pos_scores).numpy(),\n",
        "    torch.cat(all_neg_scores).numpy()\n",
        "])\n",
        "\n",
        "auc = roc_auc_score(all_labels, all_scores)\n",
        "auc_pr = average_precision_score(all_labels, all_scores)\n",
        "loss = F.binary_cross_entropy_with_logits(torch.cat(all_pos_scores + all_neg_scores),\n",
        "                                         torch.Tensor(all_labels)).item()\n",
        "\n",
        "\n",
        "\n",
        "# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬\n",
        "results = {\n",
        "    'AUC': auc,\n",
        "    'AUC_PR': auc_pr,\n",
        "    'MRR': mrr,\n",
        "    'HIT_at_K': hit_at_k,\n",
        "    'LOSS': loss}\n",
        "print('\\n', results)"
      ],
      "metadata": {
        "id": "EM-eW1RyH3K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import tensor\n",
        "from torchmetrics.retrieval import RetrievalMRR\n",
        "# logits, labels, indexes\n",
        "\n",
        "# indexes = tensor([0, 0, 0, 1, 1, 1, 1])\n",
        "# preds = tensor([0.2, 0.3, 0.5, 0.1, 0.3, 0.5, 0.2])\n",
        "# target = tensor([False, False, True, False, True, False, True])\n",
        "mrr = RetrievalMRR()\n",
        "print(f'logits: {logits.shape} , {logits}')\n",
        "print(f'labels: {labels.shape} , {labels}')\n",
        "print(f'indexes:{indexes.shape} , {indexes}')\n",
        "mrr(logits, labels, indexes=indexes)\n"
      ],
      "metadata": {
        "id": "8CgO_RPxanNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_mrr(args, model, node_emb, seeds, labels, indexes):\n",
        "    \"\"\"Compute the Mean Reciprocal Rank (MRR) for given source and destination\n",
        "    nodes.\n",
        "\n",
        "    This function computes the MRR for a set of node pairs, dividing the task\n",
        "    into batches to handle potentially large graphs.\n",
        "    \"\"\"\n",
        "\n",
        "    preds = torch.empty(seeds.shape[0], device=indexes.device)\n",
        "    mrr = RetrievalMRR()\n",
        "    seeds_src, seeds_dst = seeds.T\n",
        "    # The constant number is 1001, due to negtive ratio in the `ogbl-citation2`\n",
        "    # dataset is 1000.\n",
        "    eval_size = args.eval_batch_size * 1001\n",
        "    # Loop over node pairs in batches.\n",
        "    for start in tqdm.trange(0, seeds_src.shape[0], eval_size, desc=\"Evaluate\"):\n",
        "        end = min(start + eval_size, seeds_src.shape[0])\n",
        "\n",
        "        # Fetch embeddings for current batch of source and destination nodes.\n",
        "        h_src = node_emb[seeds_src[start:end]].to(args.device)\n",
        "        h_dst = node_emb[seeds_dst[start:end]].to(args.device)\n",
        "\n",
        "        # Compute prediction scores using the model.\n",
        "        pred = model.predictor(h_src * h_dst).squeeze()\n",
        "        preds[start:end] = pred\n",
        "    return mrr(preds, labels, indexes=indexes)"
      ],
      "metadata": {
        "id": "yaC7oi0-L_F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import average_precision_score\n",
        "from tabulate import tabulate\n",
        "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
        "\n",
        "def train_and_evaluate_link_prediction(\n",
        "    train_file,\n",
        "    test_file,\n",
        "    h_feats=16,\n",
        "    out_feats=10,\n",
        "    dropout=0.5,\n",
        "    epochs=2000,\n",
        "    lr=0.01,\n",
        "    k=10,\n",
        "    train_neg_ratio=1,\n",
        "    test_neg_ratio=10,\n",
        "    dataset_name='PersianILP_V1',\n",
        "    save_model=True):\n",
        "\n",
        "    # ======== Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ========\n",
        "    graphs = PersianDGLDataset(train_file=train_file, test_file=test_file)\n",
        "    sampler = GraphNegativeSampler(\n",
        "        graphs['train'], graphs['test'],\n",
        "        train_neg_ratio=train_neg_ratio,\n",
        "        test_neg_ratio=test_neg_ratio)\n",
        "\n",
        "    train_pos_g, train_neg_g = sampler.training_graphs\n",
        "    test_pos_g, test_neg_g = sampler.test_graphs\n",
        "\n",
        "    train_dataset = GraphBatchDataset([graphs['train']], [train_pos_g], [train_neg_g])\n",
        "    train_loader = GraphDataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "    test_dataset = GraphBatchDataset([graphs['test']], [test_pos_g], [test_neg_g])\n",
        "    test_loader = GraphDataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "    # ======== Ù…Ø¯Ù„ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø² ========\n",
        "    feats = graphs[\"train\"].ndata[\"feat\"].shape[1]\n",
        "    model = ImprovedGraphSAGE(\n",
        "        in_feats=feats,\n",
        "        h_feats=h_feats,\n",
        "        out_feats=out_feats,\n",
        "        dropout=dropout\n",
        "    )\n",
        "    pred = DotPredictor()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        itertools.chain(model.parameters(), pred.parameters()),\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    # ======== Ø¢Ù…ÙˆØ²Ø´ ========\n",
        "    def compute_loss(pos_score, neg_score):\n",
        "        scores = torch.cat([pos_score, neg_score])\n",
        "        labels = torch.cat([\n",
        "            torch.ones(pos_score.shape[0]),\n",
        "            torch.zeros(neg_score.shape[0])\n",
        "        ])\n",
        "        return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "    all_losses = []\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            batch_graph = batch[\"graph\"]\n",
        "            pos_graph = batch[\"pos_graph\"]\n",
        "            neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "            h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "            pos_score = pred(pos_graph, h)\n",
        "            neg_score = pred(neg_graph, h)\n",
        "            loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        all_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "    # ======== Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ========\n",
        "    model.eval()\n",
        "    result_dict = {dataset_name: {}}\n",
        "\n",
        "    mrr_metric = RetrievalMRR()\n",
        "    hit_rate_metric = RetrievalHitRate(top_k=k)\n",
        "    all_pos_scores = []\n",
        "    all_neg_scores = []\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        batch_graph = batch['graph']\n",
        "        pos_graph = batch['pos_graph']\n",
        "        neg_graph = batch['neg_graph']\n",
        "\n",
        "        with torch.no_grad():\n",
        "            h = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "            pos_scores = pred(pos_graph, h)\n",
        "            neg_scores = pred(neg_graph, h)\n",
        "\n",
        "            logits = torch.cat([pos_scores, neg_scores])\n",
        "            labels = torch.cat([\n",
        "                torch.ones(pos_scores.shape[0], dtype=torch.int),\n",
        "                torch.zeros(neg_scores.shape[0], dtype=torch.int)\n",
        "            ])\n",
        "            indexes = torch.cat([\n",
        "                torch.arange(pos_scores.shape[0]),\n",
        "                torch.arange(neg_scores.shape[0])\n",
        "            ])\n",
        "\n",
        "            mrr_metric.update(logits, labels, indexes)\n",
        "            hit_rate_metric.update(logits, labels, indexes)\n",
        "\n",
        "            all_pos_scores.append(pos_scores.cpu().numpy())\n",
        "            all_neg_scores.append(neg_scores.cpu().numpy())\n",
        "\n",
        "            result_dict[dataset_name]['LOSS'] = F.binary_cross_entropy_with_logits(\n",
        "                logits, labels.float()).item()\n",
        "\n",
        "    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "    result_dict[dataset_name]['MRR'] = mrr_metric.compute().item()\n",
        "    result_dict[dataset_name]['HIT_at_K'] = hit_rate_metric.compute().item()\n",
        "\n",
        "    labels_pr = np.concatenate([\n",
        "        np.ones(sum(len(x) for x in all_pos_scores)),\n",
        "        np.zeros(sum(len(x) for x in all_neg_scores))\n",
        "    ])\n",
        "    scores_pr = np.concatenate([\n",
        "        np.concatenate(all_pos_scores),\n",
        "        np.concatenate(all_neg_scores)\n",
        "    ])\n",
        "    result_dict[dataset_name]['AUC_PR'] = average_precision_score(labels_pr, scores_pr)\n",
        "\n",
        "    # ======== Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ========\n",
        "    clear_output()\n",
        "    headers = ['DataSet', 'AUC_PR', 'MRR', 'HIT_at_K', 'LOSS']\n",
        "    table_data = [[\n",
        "        dataset_name,\n",
        "        result_dict[dataset_name]['AUC_PR'],\n",
        "        result_dict[dataset_name]['MRR'],\n",
        "        result_dict[dataset_name]['HIT_at_K'],\n",
        "        result_dict[dataset_name]['LOSS']\n",
        "    ]]\n",
        "\n",
        "    print(\"\\nÙ†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´:\")\n",
        "    print(tabulate(\n",
        "        table_data,\n",
        "        headers=headers,\n",
        "        tablefmt=\"fancy_grid\",\n",
        "        floatfmt=\".4f\",\n",
        "        stralign=\"center\",\n",
        "        numalign=\"left\"\n",
        "    ))\n",
        "\n",
        "    # ======== Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ ========\n",
        "    if save_model:\n",
        "        torch.save(model.state_dict(), f'model_{dataset_name}.pth')\n",
        "        print(f\"\\nÙ…Ø¯Ù„ Ø¯Ø± 'model_{dataset_name}.pth' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
        "\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "q21qBJ85TsRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSnXtf221Rcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate_link_prediction(\n",
        "    ILP_dataset_paths['WN18RR_v1_ind']['train'],\n",
        "    ILP_dataset_paths['WN18RR_v1_ind']['test'],\n",
        "    h_feats=16,\n",
        "    out_feats=10,\n",
        "    dropout=0.5,\n",
        "    epochs=100,\n",
        "    lr=0.01,\n",
        "    k=10,\n",
        "    train_neg_ratio=1,\n",
        "    test_neg_ratio=10,\n",
        "    dataset_name='PersianILP_V1',\n",
        "    save_model=True)"
      ],
      "metadata": {
        "id": "9Aq6elSCz6B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for key, value in ILP_dataset_paths.items():\n",
        "  results = run_Inductive_link_prediction_experiment( train_file = value['train'],\n",
        "                                                      test_file  = value['test'],\n",
        "                                                      dataset_name = key,\n",
        "                                                      result_dict = results)\n",
        "  print(key, value['train'])\n",
        "  print_final_results(results)"
      ],
      "metadata": {
        "id": "vCDN0BufT1bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link Prediction With GraphSAGE + TransE**"
      ],
      "metadata": {
        "id": "KGn3o3FdB356"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.nn import SAGEConv, TransE\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# Step 0: Hyperparameter Setting\n",
        "result = {}\n",
        "epoch = 50\n",
        "result['Dataset'] = 'Persian_LP'\n",
        "\n",
        "# Step 1: Load Data\n",
        "# kg = PersianDGLDataset('/content/FarsiBase/triple.csv')\n",
        "train_file = '/content/Data_InductiveLinkPrediction/WN18RR_v1_ind/train.txt'\n",
        "test_file =  '/content/Data_InductiveLinkPrediction/WN18RR_v1_ind/test.txt'\n",
        "kg = PersianDGLDataset(train_file=train_file, test_file=test_file)\n",
        "\n",
        "train_graph = kg[\"train\"]\n",
        "test_graph = kg[\"test\"]\n",
        "feat_dim = kg[\"train\"].ndata[\"feat\"].shape[1]\n",
        "num_rels = kg[\"train\"].edata[\"e_type\"].shape[0]\n",
        "\n",
        "# Step 2: Generate Negative And Positive Graph And Batching Data\n",
        "sampler = GraphNegativeSampler(\n",
        "    graphs['train'], graphs['test'],\n",
        "    train_neg_ratio=train_neg_ratio,\n",
        "    test_neg_ratio=test_neg_ratio\n",
        ")\n",
        "train_pos_g, train_neg_g = sampler.training_graphs\n",
        "test_pos_g,  test_neg_g  = sampler.test_graphs\n",
        "train_dataset = GraphBatchDataset([kg['train']], [train_pos_g], [train_neg_g])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "test_dataset = GraphBatchDataset([kg['test']], [test_pos_g], [test_neg_g])\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, collate_fn=lambda x: x[0])\n",
        "\n",
        "# Step 3: Model Definition And Optimization\n",
        "sage_model = ImprovedGraphSAGE(in_feats=feat_dim, h_feats=64, out_feats=64)\n",
        "transe_scorer = TransE(num_rels=num_rels, feats=64)\n",
        "optimizer = torch.optim.Adam(list(sage_model.parameters()) + list(transe_scorer.parameters()), lr=0.01)\n",
        "\n",
        "# Step 4: Loss Function\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "# Step 5: Training Phase\n",
        "for epoch in tqdm(range(epoch)):\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        batch_graph = batch[\"graph\"]\n",
        "        pos_graph = batch[\"pos_graph\"]\n",
        "        neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "        # Forward\n",
        "        sage_model.train()\n",
        "        h = sage_model(batch_graph, batch_graph.ndata[\"feat\"])\n",
        "        pos_src, pos_dst = pos_graph.edges()\n",
        "        neg_src, neg_dst = neg_graph.edges()\n",
        "        pos_rels = pos_graph.edata[\"e_type\"]\n",
        "        neg_rels = neg_graph.edata[\"e_type\"]\n",
        "        pos_score = transe_scorer(h[pos_src], h[pos_dst], pos_rels)\n",
        "        neg_score = transe_scorer(h[neg_src], h[neg_dst], neg_rels)\n",
        "        loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        # print(f\"ğŸ“˜ Epoch {epoch+1} | Loss: {total_loss:.4f}\") if (epoch + 1) % 10 == 0 else None\n",
        "result[\"LOSS\"] = round(total_loss, 4)\n",
        "\n",
        "# Step 6: Evaluating Phase\n",
        "for batch in test_dataloader:\n",
        "    test_batch_graph = batch[\"graph\"]\n",
        "    test_pos_graph = batch[\"pos_graph\"]\n",
        "    test_neg_graph = batch[\"neg_graph\"]\n",
        "\n",
        "    sage_model.eval()\n",
        "    transe_scorer.eval()\n",
        "    with torch.no_grad():\n",
        "        # Calculate AUC-PR Metric\n",
        "        h = sage_model(test_batch_graph, test_batch_graph.ndata[\"feat\"])\n",
        "        pos_src, pos_dst = test_pos_graph.edges()\n",
        "        neg_src, neg_dst = test_neg_graph.edges()\n",
        "        pos_rels = test_pos_graph.edata[\"e_type\"]\n",
        "        neg_rels = test_neg_graph.edata[\"e_type\"]\n",
        "        pos_score = transe_scorer(h[pos_src], h[pos_dst], pos_rels)\n",
        "        neg_score = transe_scorer(h[neg_src], h[neg_dst], neg_rels)\n",
        "        all_scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
        "        all_labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
        "        auc_pr = average_precision_score(all_labels, all_scores)\n",
        "        result['AUC-PR'] = round(auc_pr, 4)\n",
        "\n",
        "# Step 7: Display Result\n",
        "from tabulate import tabulate\n",
        "headers = result.keys()\n",
        "values = [result.values()]\n",
        "print('\\n\\n',tabulate(values,\n",
        "                    headers=headers,\n",
        "                    tablefmt=\"grid\",\n",
        "                    floatfmt=\".4f\"))"
      ],
      "metadata": {
        "id": "VFjIgY3uaHNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}